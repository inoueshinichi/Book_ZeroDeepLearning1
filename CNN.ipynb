{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"PiBM4EsdSqd6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"26ae7bf2-3289-4126-fbc7-c4e38993a18f","executionInfo":{"status":"ok","timestamp":1535204070616,"user_tz":-540,"elapsed":756,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["# 4次元データ\n","import numpy as np\n","x = np.random.rand(10, 1, 28, 28)\n","x.shape"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 1, 28, 28)"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"w_5OVs48SqeF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ddee98fb-1fbe-46fe-9ca6-dcd2e01e9702","executionInfo":{"status":"ok","timestamp":1535204080915,"user_tz":-540,"elapsed":702,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["x[0].shape"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 28, 28)"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"jmHcR4TaSqeM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"18adbcfc-9940-454b-d00d-ca31c2058273","executionInfo":{"status":"ok","timestamp":1535204088685,"user_tz":-540,"elapsed":651,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["x[1].shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 28, 28)"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"0HNby0zeSqeQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"53250d3f-f520-47a2-e5b0-3986fbef7831","executionInfo":{"status":"ok","timestamp":1535204096493,"user_tz":-540,"elapsed":690,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["x[0, 0].shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"tqK0NJq7SqeU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3349},"outputId":"2690d39d-5843-482c-f6c4-0db504053554","executionInfo":{"status":"ok","timestamp":1535204099799,"user_tz":-540,"elapsed":655,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["x[0, 0]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.28388838e-01, 9.11925031e-02, 9.34536652e-01, 7.95296474e-01,\n","        6.43425106e-01, 7.77307434e-01, 2.14452961e-01, 5.59744277e-02,\n","        8.51225976e-01, 3.32185096e-01, 3.23585211e-01, 6.71993759e-01,\n","        7.13985088e-01, 4.39434641e-01, 8.25792353e-01, 5.47470334e-01,\n","        4.98875794e-01, 8.39821479e-01, 7.26160010e-01, 5.01616752e-01,\n","        7.90874324e-01, 6.75215918e-01, 5.31355591e-01, 3.25471716e-01,\n","        4.67945601e-01, 6.58219311e-01, 1.50375032e-01, 8.76993566e-01],\n","       [5.15460807e-01, 4.34010412e-01, 4.23271925e-01, 7.80693606e-01,\n","        9.40578471e-01, 3.99574306e-02, 1.45223266e-02, 7.39696392e-02,\n","        8.92865901e-01, 2.91608852e-02, 5.99562598e-02, 1.04950557e-02,\n","        7.39579568e-01, 8.56207863e-01, 3.90559484e-02, 8.19554833e-01,\n","        6.25835998e-01, 1.34261274e-01, 5.66109735e-01, 5.47114306e-02,\n","        1.62728358e-01, 9.74564057e-01, 5.95764979e-01, 7.66413266e-01,\n","        1.68336877e-01, 6.71345360e-01, 5.40872327e-02, 1.55059081e-01],\n","       [7.83704673e-01, 1.86149891e-01, 9.85977901e-01, 4.42106474e-01,\n","        6.78655434e-01, 5.04951404e-01, 4.26884065e-01, 3.75311947e-01,\n","        6.21928255e-01, 1.55780633e-01, 8.64794225e-01, 6.35517439e-01,\n","        2.31557214e-01, 1.47415138e-01, 7.44323558e-01, 6.99771201e-01,\n","        4.12375888e-01, 5.82164681e-01, 8.15749748e-01, 8.48770511e-01,\n","        8.73727971e-01, 7.01927035e-02, 9.94163612e-01, 1.02596177e-01,\n","        9.12400869e-01, 8.42715636e-01, 1.94402096e-01, 4.45567867e-02],\n","       [2.51330268e-02, 8.09695690e-03, 7.99310358e-01, 5.25106444e-01,\n","        6.10409219e-01, 7.58801210e-01, 4.34413809e-01, 3.08285318e-01,\n","        4.13681145e-01, 4.11859337e-01, 6.37055072e-01, 7.72534147e-01,\n","        3.43474764e-01, 7.12507855e-01, 2.70328856e-01, 3.77390064e-01,\n","        7.47924766e-01, 6.67492287e-01, 5.18663240e-01, 3.86191978e-01,\n","        8.42530496e-01, 5.29785186e-02, 1.41754876e-01, 3.20235876e-01,\n","        9.09114623e-01, 4.13080170e-02, 9.18454666e-01, 4.23003631e-02],\n","       [8.61475969e-01, 7.57882240e-01, 5.09123662e-01, 1.96439602e-01,\n","        5.58389823e-01, 6.56015150e-01, 7.96286475e-01, 6.07963917e-01,\n","        8.62235954e-01, 6.00109125e-01, 6.69995177e-01, 8.62807564e-01,\n","        6.63025403e-01, 3.01286389e-01, 7.39433494e-01, 4.65479828e-01,\n","        7.62588945e-01, 4.16667451e-01, 6.40092878e-01, 7.53771078e-01,\n","        3.89929514e-01, 5.95038737e-01, 2.45156428e-01, 1.14560198e-01,\n","        2.38344784e-01, 1.56587932e-01, 4.31193779e-01, 4.17300045e-01],\n","       [4.69325557e-02, 7.82132360e-02, 1.60282626e-01, 1.79209992e-01,\n","        8.13397558e-01, 3.19760002e-01, 2.26262711e-01, 2.95988414e-01,\n","        7.05742838e-01, 6.16931333e-01, 7.88461176e-01, 7.67271480e-02,\n","        8.82527024e-01, 6.55827236e-01, 4.62986043e-01, 1.99619767e-01,\n","        5.50389257e-01, 8.07660912e-01, 5.90074920e-01, 2.97671321e-01,\n","        3.49854747e-01, 1.79432446e-01, 1.96723794e-01, 2.58767174e-02,\n","        5.24287133e-01, 5.65961298e-01, 2.03167794e-01, 5.51630429e-01],\n","       [7.04933792e-01, 5.96930926e-01, 8.46592335e-01, 8.28391708e-01,\n","        3.87961364e-01, 1.25699491e-01, 9.12155331e-01, 9.23026341e-01,\n","        5.63202262e-01, 7.97560956e-01, 4.25295720e-02, 8.84610981e-01,\n","        8.50593533e-02, 4.09526122e-01, 4.57912123e-01, 3.62856631e-01,\n","        8.43673382e-01, 6.99174588e-01, 1.94902055e-01, 1.34102835e-01,\n","        1.01485614e-01, 4.90694262e-01, 8.22843428e-01, 5.11078659e-01,\n","        1.01384305e-01, 5.39802559e-01, 5.45529702e-01, 1.17729566e-01],\n","       [5.30449350e-01, 1.19824009e-02, 5.85628780e-01, 2.04912276e-01,\n","        6.58364825e-01, 3.77832163e-01, 9.70752730e-01, 7.48602218e-01,\n","        4.25265450e-01, 5.57841547e-01, 8.89297392e-01, 6.36760278e-01,\n","        8.76755046e-01, 3.00531053e-01, 8.18912445e-01, 3.19329858e-02,\n","        7.75901108e-01, 8.43424805e-01, 2.91295378e-01, 5.59471982e-02,\n","        2.03222161e-01, 7.62481490e-01, 4.22370605e-01, 2.07574284e-01,\n","        6.48220526e-01, 5.94231136e-02, 9.72498555e-01, 4.04604839e-02],\n","       [6.05173645e-01, 5.96994452e-01, 3.86725701e-01, 5.60035151e-01,\n","        7.93197722e-01, 9.37342987e-01, 7.99932487e-01, 8.24246908e-01,\n","        4.26423772e-01, 7.01960925e-01, 2.17342147e-01, 1.36000954e-02,\n","        7.55260575e-01, 3.21733657e-01, 3.83386906e-01, 7.52646903e-01,\n","        8.97032193e-01, 7.26398486e-01, 7.61249453e-01, 5.96023110e-01,\n","        1.26835354e-01, 1.28477417e-01, 8.78245417e-01, 4.61815705e-01,\n","        8.32624013e-01, 1.27512230e-01, 1.25416764e-01, 8.94300760e-01],\n","       [9.63402632e-01, 2.88629742e-01, 2.17702267e-01, 8.06388268e-01,\n","        5.64493094e-01, 2.85335159e-01, 4.19515177e-02, 9.91394957e-01,\n","        4.21891242e-01, 3.80259097e-01, 8.09742447e-01, 5.44464213e-01,\n","        6.94241273e-01, 6.66733842e-01, 7.40954252e-01, 2.56239482e-01,\n","        8.73189769e-02, 4.14453323e-01, 9.80445255e-01, 8.63594497e-01,\n","        7.12146137e-02, 4.65768634e-01, 9.46244769e-01, 7.10837984e-01,\n","        7.92386202e-01, 7.77476955e-01, 6.30504742e-01, 3.74133962e-01],\n","       [2.32475978e-01, 2.87151607e-01, 3.21452317e-01, 2.33170588e-01,\n","        9.64556382e-01, 5.07418316e-02, 8.79420339e-01, 4.78935619e-01,\n","        5.61064403e-01, 2.21585287e-01, 1.00216496e-01, 1.51952745e-01,\n","        1.34331023e-01, 4.05650619e-01, 3.28437039e-01, 6.49988319e-01,\n","        4.66575317e-01, 9.68447003e-01, 8.81163810e-01, 1.20781578e-01,\n","        8.21932609e-01, 2.58233236e-01, 8.34431950e-02, 5.23082678e-02,\n","        7.68911062e-01, 9.10255980e-02, 7.66562746e-01, 7.14835704e-01],\n","       [7.33702462e-01, 1.74815113e-01, 1.00193244e-01, 4.47835900e-01,\n","        5.17178807e-01, 8.27612928e-02, 3.00301064e-01, 1.15768371e-01,\n","        1.72658822e-01, 9.06691293e-01, 8.45201231e-01, 2.15870293e-02,\n","        2.70982608e-01, 6.22480452e-01, 5.71830301e-01, 4.97239174e-01,\n","        5.65675905e-01, 7.12717984e-01, 6.22491371e-01, 2.96672411e-01,\n","        2.78112386e-01, 1.34134249e-01, 8.38944282e-01, 5.74049878e-01,\n","        4.38684946e-02, 2.35315507e-01, 3.75852732e-01, 6.13426512e-01],\n","       [8.83523940e-01, 1.63139029e-01, 5.50910151e-01, 3.60740101e-01,\n","        9.44879209e-01, 3.92866885e-01, 4.24700184e-01, 4.27694799e-01,\n","        6.98634006e-01, 3.32882188e-01, 4.69307722e-01, 1.31042023e-02,\n","        3.72436327e-01, 8.52090868e-01, 8.70562620e-01, 7.92670024e-01,\n","        7.02071062e-01, 7.78224248e-01, 8.86137076e-01, 2.37346694e-01,\n","        8.65294368e-01, 3.12313904e-01, 8.26353541e-01, 3.04402980e-01,\n","        8.26475869e-01, 3.15524093e-01, 8.31866650e-01, 1.34305597e-01],\n","       [2.66678003e-01, 5.11138589e-01, 8.36103746e-01, 5.80468341e-01,\n","        2.37149690e-02, 5.06569220e-01, 9.77345566e-01, 9.31795805e-01,\n","        4.03082635e-01, 8.85514505e-01, 2.00730620e-01, 8.62521727e-01,\n","        5.93432177e-01, 9.63990116e-01, 3.72703426e-01, 9.61268066e-01,\n","        1.65209466e-02, 5.53892263e-01, 7.38373354e-01, 4.00631349e-01,\n","        4.14689678e-01, 3.33000077e-01, 4.98818569e-01, 5.36315359e-01,\n","        4.87243331e-01, 8.25916413e-01, 9.03366899e-01, 5.13040996e-01],\n","       [2.53970278e-01, 8.86705923e-01, 2.86433221e-01, 9.70748799e-01,\n","        6.14942099e-01, 3.98159151e-01, 9.18910252e-01, 5.33260689e-01,\n","        8.74841346e-02, 8.46075069e-01, 4.35578421e-01, 3.19447797e-01,\n","        8.82805157e-01, 9.93058584e-01, 8.95569638e-01, 3.96212846e-01,\n","        7.88305761e-01, 9.99329873e-01, 1.68500558e-01, 1.48999256e-01,\n","        5.62571922e-01, 4.97236399e-01, 7.86723025e-01, 5.83278295e-01,\n","        8.10592172e-01, 7.06894344e-01, 3.06367160e-01, 2.60582855e-01],\n","       [1.83476166e-01, 1.59319686e-01, 7.71966182e-01, 8.79471901e-01,\n","        6.30195999e-01, 9.02998737e-01, 4.20531431e-01, 7.60137625e-01,\n","        6.93317780e-01, 2.77232192e-01, 5.87954808e-01, 6.77853637e-01,\n","        4.51497015e-01, 1.51501591e-01, 2.87767405e-01, 9.94467772e-01,\n","        6.49696243e-01, 6.36587241e-01, 4.88555093e-01, 8.87537017e-01,\n","        4.83410414e-01, 1.38897351e-01, 4.49586558e-01, 3.71354791e-01,\n","        9.40703399e-01, 5.98812677e-01, 3.27798832e-01, 5.42222251e-01],\n","       [9.22687105e-02, 4.16668049e-01, 4.62864327e-01, 8.63446964e-01,\n","        1.83412333e-02, 6.94440456e-01, 5.92833337e-01, 9.98501079e-01,\n","        3.11469265e-01, 5.01423708e-01, 2.81750138e-01, 6.68789816e-01,\n","        6.60605795e-01, 6.01236291e-01, 2.57830176e-01, 3.06189260e-01,\n","        2.78093779e-01, 6.52251931e-01, 4.56381744e-01, 9.28076658e-01,\n","        7.70205970e-01, 8.39658284e-01, 5.54598734e-01, 8.77935908e-01,\n","        3.17553757e-01, 4.35231232e-01, 5.02434256e-01, 1.39797306e-02],\n","       [7.38275707e-01, 5.05408291e-01, 2.77266120e-01, 3.25193604e-01,\n","        1.72362350e-01, 9.61465921e-01, 4.44712501e-01, 1.20054872e-01,\n","        9.63656818e-01, 4.15809001e-01, 3.01420038e-02, 1.35678842e-01,\n","        5.71110774e-01, 1.81249226e-01, 2.99743616e-01, 7.13993881e-01,\n","        6.56295619e-01, 4.58140023e-01, 3.78483902e-01, 8.96076387e-01,\n","        1.03828550e-01, 1.66361545e-01, 6.02312133e-01, 3.66830563e-01,\n","        4.57006861e-01, 9.57331329e-01, 2.26357529e-01, 5.97858504e-01],\n","       [2.20132761e-02, 7.98847737e-01, 1.77552601e-01, 1.51388908e-01,\n","        7.58916129e-02, 6.37200804e-01, 8.91484990e-01, 6.76140186e-01,\n","        2.05632525e-01, 9.58688868e-01, 3.32948234e-02, 6.61760307e-01,\n","        1.73304639e-01, 3.16138822e-01, 1.90260702e-01, 3.60949623e-01,\n","        6.08495610e-01, 5.34278505e-01, 8.31055189e-01, 7.54159889e-01,\n","        2.49106501e-01, 2.26546354e-01, 2.51814573e-01, 7.97679006e-02,\n","        1.98647148e-01, 9.93653842e-01, 2.58329471e-01, 7.77306579e-01],\n","       [4.67565051e-01, 4.10099823e-01, 4.82144878e-01, 2.00569369e-01,\n","        4.06376551e-01, 9.15424925e-01, 8.65706482e-01, 6.48315740e-02,\n","        3.66796208e-02, 2.89046595e-01, 9.78602545e-01, 3.51572756e-01,\n","        5.37742810e-02, 5.01448069e-01, 3.81675439e-01, 6.70493167e-01,\n","        6.75042143e-01, 5.70657947e-01, 7.27681708e-01, 8.23246267e-01,\n","        8.95285972e-01, 8.17520385e-01, 4.39279208e-01, 5.04369541e-01,\n","        6.43685869e-01, 7.50676266e-02, 9.94176128e-01, 8.79585578e-01],\n","       [6.80800196e-01, 7.59928393e-01, 6.97001900e-02, 6.57318475e-01,\n","        1.78391111e-01, 8.49253539e-01, 9.21997947e-01, 8.27528575e-01,\n","        4.73657065e-01, 9.54558237e-01, 9.20529445e-01, 5.09252989e-01,\n","        8.14769194e-01, 1.94467530e-01, 9.79264745e-01, 7.33236401e-01,\n","        5.10920249e-01, 3.70967789e-01, 6.95142851e-01, 2.32149942e-01,\n","        1.86236487e-02, 8.58802888e-01, 1.06177502e-01, 3.86486701e-01,\n","        1.44622809e-02, 9.55138803e-01, 1.78513228e-01, 3.51178756e-01],\n","       [1.07270179e-01, 8.56289447e-01, 7.33948896e-01, 6.89243922e-01,\n","        5.61622933e-01, 9.82702856e-01, 3.07206069e-01, 4.14758486e-01,\n","        6.97468085e-01, 2.80488159e-01, 9.38877890e-01, 4.45268847e-01,\n","        7.00119645e-02, 5.82221916e-01, 8.37723585e-01, 1.67979572e-01,\n","        1.77028636e-01, 3.25693250e-01, 1.49061784e-01, 8.40711065e-01,\n","        9.46322782e-02, 3.92318417e-01, 6.33727884e-01, 5.06454195e-01,\n","        7.27528525e-01, 5.65823992e-01, 6.54799881e-01, 6.55131738e-01],\n","       [5.72228924e-01, 2.19197157e-01, 4.28454723e-01, 7.27382826e-01,\n","        9.43417850e-01, 1.78425098e-01, 8.58032916e-01, 3.81439078e-01,\n","        7.85106524e-01, 7.06033089e-01, 7.74302340e-01, 5.46003218e-01,\n","        7.44343288e-02, 1.92444264e-04, 2.06258407e-01, 6.08153072e-01,\n","        9.15421043e-01, 9.34834276e-01, 4.11500560e-02, 1.86372950e-01,\n","        3.53128342e-01, 4.50966935e-01, 6.90105429e-01, 7.88100466e-01,\n","        8.49764229e-01, 6.46607165e-01, 5.17083367e-01, 3.95266223e-01],\n","       [6.93552993e-01, 5.05193216e-01, 6.32807643e-01, 1.97682987e-01,\n","        4.38674880e-01, 5.46251701e-01, 9.67806224e-03, 6.14433448e-01,\n","        4.85402336e-01, 8.00078573e-01, 4.40261447e-01, 5.05496334e-01,\n","        2.47293290e-01, 4.05939652e-01, 7.56208479e-01, 1.17030620e-01,\n","        4.35483275e-01, 2.86774995e-01, 4.15857724e-01, 3.49629739e-02,\n","        1.19358536e-01, 7.91502762e-01, 9.38952075e-01, 6.34495828e-01,\n","        9.75182894e-01, 8.23055785e-02, 3.91116192e-01, 5.33044686e-01],\n","       [6.64932525e-01, 4.70176997e-01, 6.83611484e-01, 9.12854533e-01,\n","        9.49297212e-01, 1.03266507e-01, 6.97774925e-01, 5.06192144e-01,\n","        7.04543501e-01, 5.81510592e-01, 6.79781721e-01, 5.62150773e-01,\n","        3.92854835e-01, 5.60571095e-02, 7.02981945e-01, 2.86608760e-01,\n","        7.48947907e-01, 5.80269088e-01, 3.36092197e-01, 3.98932380e-01,\n","        2.72200053e-01, 7.04002520e-02, 1.43911003e-01, 8.50805918e-01,\n","        3.74181559e-01, 8.33646692e-01, 6.18152309e-01, 6.60522459e-01],\n","       [9.57846138e-01, 8.79923560e-01, 7.10399133e-01, 8.11269854e-01,\n","        6.19559224e-01, 8.16487588e-01, 1.39616909e-01, 4.73586693e-01,\n","        3.22970695e-01, 5.09204368e-01, 4.58205079e-01, 9.51008040e-01,\n","        4.27620227e-01, 1.58032659e-01, 6.83130023e-01, 4.25589649e-01,\n","        5.15259068e-01, 1.56035319e-01, 2.53448531e-01, 2.81864087e-01,\n","        8.61498379e-01, 2.28463325e-01, 8.40330196e-01, 4.04696563e-01,\n","        6.17297182e-01, 1.37872228e-01, 2.83009530e-01, 6.66677124e-01],\n","       [9.37945125e-01, 6.78351316e-01, 6.55207902e-01, 4.04110260e-01,\n","        7.83254276e-01, 9.65096299e-01, 9.10585175e-01, 9.55781999e-01,\n","        8.10233879e-01, 4.53946956e-01, 4.52572968e-01, 9.61918478e-01,\n","        4.62882435e-01, 7.13687323e-01, 2.27081852e-01, 4.20893163e-01,\n","        7.15045584e-01, 5.57905339e-01, 4.96605509e-01, 5.25623939e-01,\n","        5.24673174e-01, 6.33215192e-01, 1.95825238e-01, 9.42803378e-01,\n","        6.74960239e-01, 8.55771390e-01, 9.98337649e-01, 6.21405350e-01],\n","       [3.48780769e-01, 2.52914647e-02, 6.30171386e-01, 9.56622991e-01,\n","        6.50671091e-01, 8.33095702e-01, 7.87050596e-01, 3.46864314e-02,\n","        4.23279987e-02, 2.85363218e-01, 9.40449527e-01, 5.23732451e-01,\n","        8.58722685e-01, 9.18705309e-02, 1.89339305e-01, 5.83681874e-01,\n","        1.71600885e-01, 8.68277864e-02, 4.14777463e-01, 4.93029316e-01,\n","        7.96199123e-01, 6.34823464e-01, 5.91202284e-01, 8.79241610e-01,\n","        8.31065379e-01, 9.65792566e-01, 2.68901695e-01, 9.63047105e-01]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"iJPYU4t6SqeX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"59f7b8b6-b2c5-4e68-f239-68d40bc64cfe","executionInfo":{"status":"ok","timestamp":1535204114381,"user_tz":-540,"elapsed":669,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["# numpy padding\n","# 1次元配列\n","a = [2, 3]\n","b = np.pad(a, [1,0], \"constant\")\n","print(b) # 先頭に1個、末尾に0個 0パディング\n","c = np.pad(a, [1,2], \"constant\")\n","print(c) # 先頭に1個、末尾に2個 0パディング\n","\n","# 2次元配列\n","d = [[1,2], [3,4]]\n","e = np.pad(d, [(1,2),(3,4)], \"constant\")\n","print(e) # 行の先頭に1行、行末に2行、左の列に3行、右の列に4行"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[0 2 3]\n","[0 2 3 0 0]\n","[[0 0 0 0 0 0 0 0 0]\n"," [0 0 0 1 2 0 0 0 0]\n"," [0 0 0 3 4 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]]\n"],"name":"stdout"}]},{"metadata":{"id":"6RQMW6eCSqeb","colab_type":"code","colab":{}},"cell_type":"code","source":["#np.zeros((2, 3, 3, 3, 2, 2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3fg5rRGlSqed","colab_type":"code","colab":{}},"cell_type":"code","source":["# im2col(image to column)\n","\n","def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n","    # input_data : (dataNum, ch, height, width)\n","    # pad : パディング\n","    \n","    # return col: 2次元配列\n","    \n","    N, C, H, W = input_data.shape\n","    out_h = (H + 2*pad - filter_h) // stride + 1\n","    out_w = (W + 2*pad - filter_w) // stride + 1\n","    \n","    \n","                             # 個数方向, ch方向, 行方向、 列方向\n","    img = np.pad(input_data, [(0,0), (0,0), (pad,pad), (pad,pad)], 'constant')\n","    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n","    \n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n","    \n","    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n","    return col"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pxVt-qmwSqef","colab_type":"code","colab":{}},"cell_type":"code","source":["def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n","    \"\"\"\n","\n","    Parameters\n","    ----------\n","    col :\n","    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n","    filter_h :\n","    filter_w\n","    stride\n","    pad\n","\n","    Returns\n","    -------\n","\n","    \"\"\"\n","    N, C, H, W = input_shape\n","    out_h = (H + 2*pad - filter_h) // stride + 1\n","    out_w = (W + 2*pad - filter_w) // stride + 1\n","    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n","\n","    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n","\n","    return img[:, :, pad:H + pad, pad:W + pad]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MXxGkLx-Sqeh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"55cd6bb1-b5b9-423f-dfce-dee48f562057","executionInfo":{"status":"ok","timestamp":1535204499396,"user_tz":-540,"elapsed":895,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["# im2colを使う\n","x1 = np.random.rand(1,3,7,7) # 1個のデータ\n","fil_h = 5\n","fil_w = 5\n","col1 = im2col(x1, fil_h, fil_w, stride=1, pad=0)\n","print(col1.shape)\n","\n","x2 = np.random.rand(10, 3, 7, 7) # 10個のデータ\n","col2 = im2col(x2, fil_h, fil_w, stride=1, pad=0)\n","print(col2.shape) # 9行75列の行列が行方向に10個連結している"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(9, 75)\n","(90, 75)\n"],"name":"stdout"}]},{"metadata":{"id":"P1BX7mb4Sqek","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convolutionレイヤ\n","class Convolution:\n","    # フィルターサイズが重みW\n","    def __init__(self, W, b, stride=1, pad=0):\n","        self.W = W\n","        self.b = b\n","        self.stride = stride\n","        self.pad = pad\n","        \n","        # backward用\n","        self.x = None\n","        self.col = None\n","        self.col_w = None\n","        \n","        self.dW = None\n","        self.db = None\n","        \n","    def forward(self, x):\n","        # xは４次元データ\n","        FN, C, FH, FW = self.W.shape\n","        N, C, H, W = x.shape\n","        out_h = (H + 2*self.pad - FH) // self.stride + 1\n","        out_w = (W + 2*self.pad - FW) // self.stride + 1\n","        \n","        col = im2col(x, FH, FW, self.stride, self.pad)\n","        # フィルタの個数は入力データN個(バッチサイズ)全体でFN個のみ\n","        col_W = self.W.reshape(FN, -1).T # フィルターの展開 # N個のそれぞれの1つ目のフィルタによるブロックは順番に行に挿入される\n","        out = np.dot(col, col_W) + self.b\n","        \n","        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) # (N, FN, out_h, out_w)\n","        \n","        self.x = x\n","        self.col = col\n","        self.col_W = col_W\n","        return out\n","    \n","    def backward(self, dout):\n","        FN, C, FH, FW = self.W.shape\n","        # dout(N, FN, out_h, out_w) -> (N, out_h, out_w, FN)\n","        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN) # (N, FN, out_h, out_w)を(#(N*フィルタの適用領域の個数), FN)に変換\n","        \n","        self.db = np.sum(dout, axis=0) # 各フィルタ(列)ごとにバッチN*(1個あたりC*FH*FW)個の微分値の合計 注) １個のフィルタに対して、バイアス変数は1個\n","        self.dW = np.dot(self.col.T, dout) # shape(C*FH*FW, FN) = col.shape(N*フィルタの適用領域の個数, C*FH*FW)^T・dout.shape(N*フィルタの適用領域の個数, FN)\n","        \"\"\"\n","        self.colとdoutの行数=N*フィルタの適用領域の個数のデータ構造(行と列)\n","            FilArea[0] = (C[0]X[0,0], ..., C[0]X[h,w], C[1]X[0,0], ..., C[1]X[h,w], C[2]X[0,0], ..., C[2]X[h,w])\n","            .\n","            .\n","            .\n","            FilArea[i] = (C[0]X[i*h,i*w], ..., C[0]X[(i+1)*h,(i+1)*w], ..., C[1]X[i*h,i*w], ..., C[1]X[(i+1)*h,(i+1)*w], C[2]X[i*h,i*w], ..., C[2]X[(i+1)*h, (i+1)*w])\n","            .\n","            .\n","            .\n","            FilArea[FN-1] = ....\n","        \"\"\"     \n","        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n","        \n","        dcol = np.dot(dout, self.col_W.T) # 2次元\n","        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad) # 4次元\n","        \n","        # Convolution内部では4次元->2次元->2次元\n","        return dx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ucQPd454Sqem","colab_type":"code","colab":{}},"cell_type":"code","source":["# Poolingレイヤ\n","class Pooling:\n","    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n","        self.pool_h = pool_h\n","        self.pool_w = pool_w\n","        self.stride = stride\n","        self.pad = pad\n","        \n","        # backward用\n","        \n","        self.x = None\n","        self.arg_max = None\n","        \n","        \n","    def forward(self, x):\n","        N, C, H, W = x.shape\n","        out_h = int((H - self.pool_h)/self.stride + 1)\n","        out_w = int((W - self.pool_w)/self.stride + 1)\n","        \n","        # 展開(1)\n","        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n","        col = col.reshape(-1, self.pool_h * self.pool_w) # 1チャネルの1フィルタの値が列をなす行を作る\n","        \n","        # 最大値(2)\n","        out = np.max(col, axis=1)\n","        \n","        # backward用\n","        arg_max = np.argmax(col, axis=1)\n","        self.arg_max = arg_max\n","        \n","        # 整形(3)\n","        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n","        \n","        self.x = x\n","        \n","        \n","        return out\n","    \n","    def backward(self, dout):\n","        dout = dout.transpose(0, 2, 3, 1) # (N, C, out_h, out_w) -> (N, out_h, out_w, C)\n","\n","        pool_size = self.pool_h*self.pool_w\n","        dmax = np.zeros((dout.size, pool_size)) # 1列の個数は1フィルタブロック*N\n","\n","        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n","        dmax = dmax.reshape(dout.shape + (pool_size,))\n","\n","        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n","        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n","\n","        return dx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xI9_wbaPSqeo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"de20ee19-949e-4566-d71b-4ba0b9699094","executionInfo":{"status":"ok","timestamp":1535208227489,"user_tz":-540,"elapsed":582,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["_fn = 5\n","_c = 3\n","_fh = 10\n","_fw = 10\n","x = np.random.randn(_fn, _c, _fh, _fw)\n","print(x.shape)\n","x.size"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(5, 3, 10, 10)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1500"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"HWdEufPhSqer","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3638},"outputId":"fd2269ae-5b26-4272-9bcc-e429f938917f","executionInfo":{"status":"ok","timestamp":1535208269171,"user_tz":-540,"elapsed":556,"user":{"displayName":"井上真一","photoUrl":"//lh5.googleusercontent.com/-ptIcKi-iHok/AAAAAAAAAAI/AAAAAAAAF6k/zIZhVb5pQxw/s50-c-k-no/photo.jpg","userId":"109156496964067986275"}}},"cell_type":"code","source":["x"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[[ 1.95999910e+00, -3.69619061e-01,  5.85049288e-01, ...,\n","          -1.92869820e-01, -1.84721524e+00, -6.54444815e-01],\n","         [ 5.58343198e-01, -4.31995054e-01,  6.43679583e-01, ...,\n","          -2.92227865e-01, -1.00044155e+00, -5.70116568e-02],\n","         [-1.74983608e+00, -3.94987162e-01, -4.49879308e-01, ...,\n","           5.09528315e-01, -5.43607523e-01, -1.69494031e+00],\n","         ...,\n","         [-2.44370517e-01,  1.49755332e+00, -2.45072023e-01, ...,\n","          -8.15677312e-01, -5.96005853e-01, -1.43706842e+00],\n","         [-9.56258094e-02,  3.56651946e-01, -1.75154214e+00, ...,\n","           3.62714826e-01, -2.21143574e+00, -1.77450267e-01],\n","         [ 1.16862099e+00, -9.44271699e-01, -3.36795980e-01, ...,\n","           7.98724341e-02,  7.33514740e-01, -1.30689234e+00]],\n","\n","        [[ 7.89448369e-01, -1.39614392e+00,  1.12698452e-01, ...,\n","           1.00921511e-01,  8.49176415e-02, -2.61764964e-01],\n","         [ 6.71187963e-01, -3.26435646e-01,  2.33604767e-01, ...,\n","           3.39649902e-01, -3.21657769e-01,  2.68231578e-01],\n","         [-2.33894755e-01, -1.09604054e+00, -1.45152314e+00, ...,\n","           1.37819264e+00,  6.74322905e-01,  3.50223728e-01],\n","         ...,\n","         [ 5.18040062e-01,  3.41744003e-01, -2.12532475e-01, ...,\n","          -1.70917487e-01,  6.39995508e-01,  1.98678148e-01],\n","         [ 2.26392532e-01,  1.78918259e+00,  5.16688574e-02, ...,\n","           2.17101884e-01, -3.08414843e-01,  1.14216397e+00],\n","         [-3.00450059e-01,  1.46373426e+00,  1.32231193e+00, ...,\n","          -2.03185166e+00,  4.45031044e-01, -2.52182101e+00]],\n","\n","        [[-7.08958940e-01, -1.21601057e+00,  1.21419385e+00, ...,\n","           7.86723845e-02, -4.62082669e-01,  1.08608723e+00],\n","         [ 1.60116779e+00, -1.61011466e+00,  7.34113530e-01, ...,\n","          -3.00199994e+00, -9.12352704e-01, -9.58285787e-01],\n","         [ 1.33137243e-01,  8.95907365e-01, -8.11839769e-01, ...,\n","          -2.18106869e+00,  1.09485858e+00, -3.56068150e-01],\n","         ...,\n","         [-3.36989628e-01,  2.44379522e-01,  1.06488395e-03, ...,\n","           1.21552043e+00, -9.99981517e-01,  1.46123329e+00],\n","         [-5.58563417e-01,  3.38834197e-01,  1.01933230e+00, ...,\n","          -1.35150426e+00, -5.87484531e-01,  1.40723784e+00],\n","         [-1.17197570e+00,  1.15287614e-01,  1.18856785e+00, ...,\n","          -1.29779879e+00,  6.17349724e-01,  3.00601169e-03]]],\n","\n","\n","       [[[-3.31256497e-01,  3.91080933e-01, -2.37309273e+00, ...,\n","           1.10154184e+00, -1.27139211e+00,  1.44810930e+00],\n","         [-6.60347866e-01,  2.64306158e-01,  2.82022511e+00, ...,\n","           9.01719313e-01,  5.16190357e-01,  4.04011332e-01],\n","         [ 2.65645009e-01, -1.49723086e+00, -5.73853504e-01, ...,\n","           3.35207740e-01,  1.36232446e+00,  1.12717075e+00],\n","         ...,\n","         [-6.79230027e-01, -1.89728403e+00,  3.87211269e-01, ...,\n","          -1.88394738e+00, -5.38181167e-01, -3.71287281e-01],\n","         [ 1.25773378e-01, -5.55112774e-01,  1.13464368e+00, ...,\n","           2.55918754e-01, -8.40014993e-02,  3.49046344e-01],\n","         [-7.76275527e-01, -8.65460433e-01, -4.97488355e-01, ...,\n","           7.03469155e-01,  2.55299254e-01, -2.68821353e-01]],\n","\n","        [[ 8.21840047e-02, -4.58160972e-02,  1.88893360e-01, ...,\n","           7.92653918e-01,  2.06180846e-01, -1.67124481e+00],\n","         [-1.83665741e-01, -7.77832880e-02,  8.87663097e-01, ...,\n","          -1.17343786e-01,  5.25406788e-01,  9.80456140e-01],\n","         [-6.14773676e-01,  2.15094696e+00,  2.86101671e-01, ...,\n","           1.10093050e-01,  8.63587328e-01, -7.41910387e-01],\n","         ...,\n","         [-1.13053205e+00,  1.24445197e+00,  3.18606527e-01, ...,\n","           1.25958580e+00, -8.84131691e-01,  7.90908983e-01],\n","         [-1.54169536e+00,  2.84193654e-02, -5.25568947e-01, ...,\n","          -8.13139899e-01, -1.15502812e+00,  6.28146621e-01],\n","         [ 1.01309864e+00, -1.44614344e+00, -1.27967265e+00, ...,\n","           5.94319922e-01,  9.41246913e-02, -1.74140468e+00]],\n","\n","        [[ 9.97959612e-01, -5.36430867e-02, -1.49187879e+00, ...,\n","           1.05569168e+00, -7.66484577e-01,  2.75148729e-01],\n","         [-5.06012368e-02,  9.51022653e-01,  1.20298300e+00, ...,\n","           4.68656279e-01,  7.70144617e-01,  3.60114389e-02],\n","         [ 1.14921927e+00, -3.11389848e-01, -1.90523061e+00, ...,\n","           6.37880131e-01,  5.31278832e-01, -5.59037988e-01],\n","         ...,\n","         [-5.79099677e-01,  1.28506139e+00, -8.91183505e-01, ...,\n","           1.05418069e-01, -9.73355406e-02, -6.12762789e-01],\n","         [ 8.86113009e-01, -9.02833064e-01,  2.01551742e+00, ...,\n","          -2.96790123e-01,  1.76442289e-01, -1.56266121e+00],\n","         [-1.92287341e+00, -9.49417194e-01, -4.66326700e-01, ...,\n","           1.30010236e+00,  1.86563810e+00,  8.69708422e-01]]],\n","\n","\n","       [[[ 1.74545787e+00,  2.23764537e+00,  1.96175979e+00, ...,\n","          -1.25321840e-01,  1.46504691e+00, -6.91284627e-01],\n","         [ 6.41045424e-01,  1.71946317e-01,  1.97296488e+00, ...,\n","           2.30881183e-01,  5.26229806e-01,  7.68050273e-01],\n","         [-1.40196782e+00, -7.36010617e-01, -1.40767879e+00, ...,\n","           1.81049527e-01, -5.45446791e-01,  9.87674348e-01],\n","         ...,\n","         [-1.35973133e+00,  9.88647434e-01,  2.00503656e-01, ...,\n","           2.18308956e+00,  2.53236735e-01, -6.80052773e-01],\n","         [ 1.70182876e-02, -7.05539891e-01, -1.57669051e-01, ...,\n","           8.14857010e-01,  4.18766107e-01, -6.76633248e-01],\n","         [ 3.09983434e-01,  2.85728854e-01,  9.95021468e-01, ...,\n","          -1.27366958e+00,  9.61537489e-01, -8.29956338e-01]],\n","\n","        [[ 1.15602861e+00,  1.43089290e+00, -1.14500254e+00, ...,\n","          -1.63476007e-01,  2.38240727e+00,  8.53333939e-01],\n","         [-9.30526847e-01,  1.50402566e-02,  2.13388482e+00, ...,\n","           3.27328568e-01,  1.56298309e+00, -5.92828945e-01],\n","         [-5.19367598e-01, -3.61543547e-01, -8.08542913e-01, ...,\n","          -1.39765650e+00,  9.27660274e-01, -7.66568970e-01],\n","         ...,\n","         [ 1.46513555e+00, -1.02867607e-01, -5.37460286e-01, ...,\n","           5.41237226e-01, -1.31044222e+00,  5.16373524e-01],\n","         [ 1.30197889e+00,  3.89051768e-01, -2.94841807e-01, ...,\n","           1.22908098e+00,  8.44023142e-01,  4.04436520e-01],\n","         [ 9.52850777e-01,  2.87319507e-01,  7.56803101e-01, ...,\n","          -1.10851931e+00,  3.48408968e-01, -1.00793302e+00]],\n","\n","        [[-1.66538340e-01,  1.82016369e+00,  2.25356139e-01, ...,\n","          -1.59740459e-01, -1.08473107e+00, -4.02043474e-02],\n","         [ 1.74736411e+00,  1.12930680e-01, -1.14307733e+00, ...,\n","          -9.10299535e-01, -1.30206832e+00,  1.12921274e+00],\n","         [-1.36408586e-01,  1.32981385e+00,  1.45380122e+00, ...,\n","          -8.13190359e-01,  7.32532492e-01,  1.13379847e+00],\n","         ...,\n","         [ 9.99328410e-01, -1.74434672e+00, -1.26323026e-01, ...,\n","          -6.14445997e-01,  2.35752886e-01, -1.54698012e-01],\n","         [ 6.69666852e-01,  4.95812865e-01,  5.31542531e-01, ...,\n","           1.46413186e-01,  7.68116538e-01,  6.22048150e-01],\n","         [ 1.32108649e+00, -7.90455845e-01, -1.12672085e+00, ...,\n","          -2.27694595e-01, -1.16546773e-01,  2.42624568e-01]]],\n","\n","\n","       [[[ 9.67212837e-02,  3.10574681e-01, -8.62653521e-01, ...,\n","          -6.33431450e-01,  9.90139855e-01, -1.09921652e+00],\n","         [ 2.41485974e-01,  3.95691773e-01, -1.13087068e+00, ...,\n","          -5.57062789e-01,  5.81942828e-01, -8.27091082e-01],\n","         [-7.04803327e-02, -3.38016293e-01, -1.31679542e+00, ...,\n","          -6.86640824e-01,  1.22087304e+00, -6.24642848e-01],\n","         ...,\n","         [ 1.69019506e+00,  1.13107170e+00, -2.34280863e+00, ...,\n","          -1.00308047e+00,  6.95800596e-01, -2.11189897e-01],\n","         [-3.97241276e-01, -3.31224885e-02,  1.00154096e+00, ...,\n","           1.25973627e+00, -3.29294955e-02,  5.73150384e-01],\n","         [-1.10548538e+00,  7.26481899e-01, -8.69078030e-02, ...,\n","          -5.51560866e-01, -7.18987096e-01, -1.63336193e+00]],\n","\n","        [[-1.28547257e+00,  1.74440552e-01, -2.68302780e+00, ...,\n","           2.46403603e-01,  1.20185223e+00,  5.34235971e-01],\n","         [ 9.22862165e-01, -5.65098376e-01,  3.49868896e-01, ...,\n","           8.29264982e-01,  5.98817310e-01, -3.18302558e-01],\n","         [ 2.39880472e-01, -5.89450623e-02, -6.10572410e-02, ...,\n","          -3.11436694e-01,  3.44391091e-01,  5.59767941e-01],\n","         ...,\n","         [ 3.51892413e-01, -1.74101298e+00, -9.84816805e-01, ...,\n","           6.99164248e-01, -1.13969064e+00, -3.60388627e-01],\n","         [-1.26053840e+00,  1.34434986e+00,  1.00017825e+00, ...,\n","           1.24708910e+00,  2.64093886e-02,  1.00495526e+00],\n","         [-2.42322015e-01, -1.20288828e-01,  5.12749706e-01, ...,\n","           4.77440159e-01, -6.74831470e-01,  1.36285043e+00]],\n","\n","        [[ 1.77240674e+00, -1.13772985e+00,  7.46932133e-01, ...,\n","          -2.13505337e-02,  7.03604422e-01,  7.68932861e-01],\n","         [ 1.47419318e+00, -3.51736417e-01, -1.38113332e-01, ...,\n","           8.20126139e-01, -2.67108923e-01,  1.93699293e+00],\n","         [-2.47636709e-01, -8.97568169e-01, -4.20616504e-01, ...,\n","           2.17603706e-01, -5.90697700e-01,  2.98971751e-01],\n","         ...,\n","         [-5.42519871e-01, -4.13007567e-02,  9.01285276e-01, ...,\n","          -4.57007634e-01,  3.08725718e+00, -7.09316658e-01],\n","         [ 9.12899848e-02, -9.25161490e-01, -2.14982478e+00, ...,\n","           1.06594298e+00, -1.65548285e-01, -5.40751343e-01],\n","         [-1.61455830e+00,  1.01264122e+00, -1.60080745e-01, ...,\n","          -3.52618443e-01,  4.05493337e-01, -8.60775052e-01]]],\n","\n","\n","       [[[ 2.70487371e-01, -7.55322706e-01, -1.35699978e+00, ...,\n","          -1.76982200e-01,  5.08687916e-01,  4.80361314e-01],\n","         [ 9.44433683e-02, -9.31671199e-01,  2.33906164e-01, ...,\n","           7.22075738e-01, -3.14823741e-01,  1.39810101e+00],\n","         [ 4.16631649e-02,  8.64864040e-01, -1.21078588e+00, ...,\n","           1.02363728e+00, -7.57456747e-01, -5.80818476e-01],\n","         ...,\n","         [-1.73333812e+00,  3.48302907e-01, -7.53770147e-01, ...,\n","          -1.07179108e+00,  1.74497336e-01,  6.57832357e-01],\n","         [ 4.70501372e-02,  7.22769398e-01, -1.69388917e+00, ...,\n","           3.09967845e-01,  9.35418882e-01, -1.06848808e+00],\n","         [-2.54475493e-01,  8.77205480e-01, -3.12800971e-01, ...,\n","           4.04872508e-01, -1.30716044e+00,  7.86940692e-03]],\n","\n","        [[ 5.08006866e-01,  8.90158638e-01,  8.82831900e-02, ...,\n","          -8.45627460e-01,  9.46529024e-01, -1.52202040e+00],\n","         [-2.90174743e-01,  1.34273525e+00,  5.17070488e-02, ...,\n","           1.06172916e+00, -3.56417551e-01, -1.46883421e+00],\n","         [-7.69439811e-01, -5.30254738e-01,  7.22752953e-01, ...,\n","          -1.26116233e+00,  2.48797135e-01, -1.08691640e+00],\n","         ...,\n","         [ 2.79119614e-01,  1.99695276e+00,  2.17832124e-01, ...,\n","          -6.97719577e-01, -9.37459485e-02,  2.76194167e-03],\n","         [ 1.01194515e+00, -6.33981739e-01,  9.18175463e-01, ...,\n","           5.32957944e-02, -1.75844147e+00, -1.03783802e+00],\n","         [-9.76420784e-01, -1.04427719e+00,  9.43400019e-01, ...,\n","          -5.66911520e-01,  4.13648233e-01,  8.48594341e-01]],\n","\n","        [[-2.34003001e+00, -9.79257785e-03,  1.63472057e+00, ...,\n","          -3.74992853e-01,  2.63730341e-01, -5.11101961e-01],\n","         [-6.68349907e-01,  7.15218267e-01, -2.72651802e+00, ...,\n","          -1.62438023e-01, -6.71653646e-01,  4.85679980e-01],\n","         [ 2.08534811e+00, -8.20931775e-01,  5.11245791e-01, ...,\n","           1.42705018e-01, -2.50471426e-01,  1.25716765e-01],\n","         ...,\n","         [-1.09286002e+00, -1.67732446e+00,  2.18265040e-01, ...,\n","           1.35911851e+00, -1.82099395e+00,  3.65050353e-01],\n","         [-9.57585645e-02,  2.42315427e-01,  6.29462654e-01, ...,\n","           5.64920335e-01, -6.43751778e-01, -1.15826735e+00],\n","         [-6.32745326e-01,  5.51543456e-02,  5.02900791e-01, ...,\n","           6.18040539e-01, -7.75220672e-01, -1.03822093e+00]]]])"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"-AW-bO9TSqet","colab_type":"code","colab":{},"outputId":"87a05aff-2109-4c23-98a2-8553967c29f7"},"cell_type":"code","source":["x.flatten()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-2.45271193, -0.97364744,  0.54538116, -1.50692132, -0.33446808,\n","        0.07275991, -0.14843256, -1.12671648,  0.43428211, -0.1616315 ,\n","        1.55441513,  1.03600255, -0.84353015, -0.63776027,  1.26770957,\n","       -0.85110847,  0.64433424, -0.30993471, -0.11469489,  0.94370336,\n","        0.75526105, -1.37770427,  0.43196037, -0.09814835,  0.99672789,\n","       -0.24995163, -0.14984452, -0.07201555, -0.19426536, -0.5466863 ,\n","       -1.06022015, -0.33362985,  0.56152968,  0.87063086, -2.18383873,\n","        1.58048642,  1.07670277, -0.60168269,  0.5722494 , -1.46550435,\n","        0.51728742,  1.02556607, -0.61469622, -1.03680352, -1.39902381,\n","        0.00622228, -0.34442495,  1.61176446])"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"1Yex2MyOSqew","colab_type":"code","colab":{}},"cell_type":"code","source":["def affine(x, w, b):\n","    return np.dot(x, w) + b\n","\n","class Affine:\n","    def __init__(self, W, b):\n","        self.W = W\n","        self.b = b\n","        self.x = None\n","        self.dW = None\n","        self.db = None\n","        \n","        # テンソル対応\n","        self.original_x_shape = None\n","        \n","    def forward(self, x):\n","        #self.x = x\n","        \n","        # テンソル対応\n","        self.original_x_shape = x.shape\n","        x = x.reshape(x.shape[0], -1) # 4次元を2次元に変換\n","        self.x = x\n","        \n","        out = np.dot(x, self.W) + self.b\n","        return out\n","    \n","    def backward(self, dout):\n","        dx = np.dot(dout, self.W.T)\n","        self.dW= np.dot(self.x.T, dout)\n","        self.db = np.sum(dout, axis=0)\n","        \n","        # 入力データの形状に戻す（テンソル対応）\n","        dx = dx.reshape(*self.original_x_shape)\n","        \n","        return dx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pfdUytPdSqex","colab_type":"code","colab":{}},"cell_type":"code","source":["def relu(x):\n","    return np.max(0, x)\n","\n","class Relu:\n","    def __init__(self):\n","        self.mask = None\n","        \n","    def forward(self, z):\n","        self.mask = (z <= 0)\n","        out = z.copy()\n","        out[self.mask] = 0\n","        return out\n","    \n","    def backward(self, dout):\n","        # Reluレイヤのforward入力とbackward出力は同じ次元\n","        dout[self.mask] = 0\n","        return dout"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kYHcxfrMSqez","colab_type":"code","colab":{}},"cell_type":"code","source":["def softmax(x):\n","    if x.ndim == 2:\n","        x = x.T\n","        x = x - np.max(x, axis=0)\n","        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n","        return y.T\n","    \n","    x = x - np.max(x) # オーバーフロー対策\n","    y = np.exp(x) / np.sum(np.exp(x))\n","    return y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OL3VPxyuSqe1","colab_type":"code","colab":{}},"cell_type":"code","source":["def cross_entropy_error(y, t):\n","    \"\"\"\n","    # 交差エントロピーの入力(softmaxの出力)は1xN\n","    if y.ndim == 1: # 1サンプルのみのとき\n","        z = z.reshape(1, z.size) # (*,) -> (1,*)に変更\n","        y = y.reshape(1, y.size)\n","    \n","    batch_size = y.shape[0]\n","    #print(\"y.shape\", y.shape)\n","    #print(\"t.shape\", t.shape)\n","    #print(\"y.size\", y.size)\n","    #print(\"t.size\", t.size)\n","    # テストデータがラベリングのとき\n","    if y.size != t.size:\n","        t_one_hot = np.zeros_like(y, dtype=np.int) # one_hot表現の雛形\n","        for index in range(batch_size):\n","            #print('index', index)\n","            #print('t[index]', t[index])\n","            t_one_hot[index, int(t[index])] = 1\n","        t = t_one_hot # 変換\n","    \n","    # tをone-hot表現に変換してから交差エントロピーを計算する\n","    return -np.sum(t * np.log(y)) / batch_size \n","    \"\"\"\n","    # 以下、サンプル通り\n","    if y.ndim == 1:\n","        t = t.reshape(1, t.size)\n","        y = y.reshape(1, y.size)\n","        \n","    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n","    if t.size == y.size:\n","        t = t.argmax(axis=1)\n","             \n","    #print('t:', t)        \n","    batch_size = y.shape[0]\n","    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ilxyf7hMSqe2","colab_type":"code","colab":{}},"cell_type":"code","source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None\n","        self.y = None # Softmaxの出力\n","        self.t = None\n","        self.x = None\n","        \n","    def forward(self, x, t):\n","        self.t = t\n","        self.x = x\n","        self.y = softmax(x)\n","        \n","        #print('self.y', self.y.shape)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","        \n","        return self.loss\n","    \n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        \n","        # テストデータがone-hot-vector表現の場合\n","        if self.t.size == self.y.size:\n","            dx = (self.y - self.t) / batch_size # サンプル1個あたりの誤差勾配\n","        else:\n","            dx = self.y.copy()\n","            dx[np.arange(batch_size), self.t] -= 1\n","            dx = dx / batch_size\n","            \n","        return dx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RoViu5umSqe4","colab_type":"code","colab":{}},"cell_type":"code","source":["def numerical_gradient(f, x):\n","    h = 1e-4 # 0.0001\n","    grad = np.zeros_like(x)\n","    \n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","    while not it.finished:\n","        idx = it.multi_index\n","        tmp_val = x[idx]\n","        x[idx] = float(tmp_val) + h\n","        fxh1 = f(x) # f(x+h)\n","        \n","        x[idx] = tmp_val - h \n","        fxh2 = f(x) # f(x-h)\n","        grad[idx] = (fxh1 - fxh2) / (2*h)\n","        \n","        x[idx] = tmp_val # 値を元に戻す\n","        it.iternext()   \n","        \n","    return grad"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y1SD0PFBSqe5","colab_type":"code","colab":{}},"cell_type":"code","source":["# CNNの実装\n","# [Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax]\n","from collections import OrderedDict\n","import numpy as np\n","import pickle\n","\n","class SimpleConvNet:\n","    # input_dim=(チャネル、画像の高さ, 画像の幅)\n","    def __init__(self, \n","                 input_dim=(1, 28, 28), \n","                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n","                 hidden_size=100,\n","                 output_size=10,\n","                 weight_init_std=0.01):\n","        \n","        filter_num = conv_param['filter_num']\n","        filter_size = conv_param['filter_size']\n","        filter_pad = conv_param['pad']\n","        filter_stride = conv_param['stride']\n","        \n","        input_size = input_dim[1] # Height and Width of img\n","        conv_output_size = (input_size + 2*filter_pad - filter_size)/filter_stride + 1\n","        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n","        \n","        # 重みパラメータの初期化を行うパート\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n","        self.params['b1'] = np.zeros(filter_num)\n","        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size) # 入力数, 出力数\n","        self.params['b2'] = np.zeros(hidden_size)\n","        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b3'] = np.zeros(output_size)\n","        \n","        # レイヤの作成\n","        self.layers = OrderedDict()\n","        self.layers['Conv1'] = Convolution(self.params['W1'], \n","                                           self.params['b1'], \n","                                           conv_param['stride'], \n","                                           conv_param['pad'])\n","        self.layers['Relu1'] = Relu()\n","        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n","        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n","        self.layers['Relu2'] = Relu()\n","        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n","        \n","        self.last_layer = SoftmaxWithLoss()\n","        \n","    \n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","        return x\n","    \n","    \n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return self.last_layer.forward(y, t)\n","\n","    \n","    def gradient(self, x, t):\n","        # forward\n","        self.loss(x, t)\n","        \n","        # backward\n","        dout = 1\n","        dout = self.last_layer.backward(dout)\n","        \n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","            \n","        grads = {}\n","        grads['W1'] = self.layers['Conv1'].dW\n","        grads['b1'] = self.layers['Conv1'].db\n","        grads['W2'] = self.layers['Affine1'].dW\n","        grads['b2'] = self.layers['Affine1'].db\n","        grads['W3'] = self.layers['Affine2'].dW\n","        grads['b3'] = self.layers['Affine2'].db\n","        \n","        return grads\n","    \n","    \n","    def accuracy(self, x, t, batch_size=100):\n","        if t.ndim != 1 : t = np.argmax(t, axis=1)\n","        \n","        acc = 0.0\n","        \n","        for i in range(int(x.shape[0] / batch_size)):\n","            tx = x[i*batch_size:(i+1)*batch_size]\n","            tt = t[i*batch_size:(i+1)*batch_size]\n","            y = self.predict(tx)\n","            y = np.argmax(y, axis=1)\n","            acc += np.sum(y == tt) \n","        \n","        return acc / x.shape[0]\n","    \n","    \n","    def numerical_gradient(self, x, t):\n","        \"\"\"勾配を求める（数値微分）\n","\n","        Parameters\n","        ----------\n","        x : 入力データ\n","        t : 教師ラベル\n","\n","        Returns\n","        -------\n","        各層の勾配を持ったディクショナリ変数\n","            grads['W1']、grads['W2']、...は各層の重み\n","            grads['b1']、grads['b2']、...は各層のバイアス\n","        \"\"\"\n","        loss_w = lambda w: self.loss(x, t)\n","\n","        grads = {}\n","        for idx in (1, 2, 3):\n","            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n","            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n","            \n","        return grads\n","    \n","    \n","    def save_params(self, file_name=\"params.pkl\"):\n","        params = {}\n","        for key, val in self.params.items():\n","            params[key] = val\n","        with open(file_name, 'wb') as f:\n","            pickle.dump(params, f)\n","\n","            \n","    def load_params(self, file_name=\"params.pkl\"):\n","        with open(file_name, 'rb') as f:\n","            params = pickle.load(f)\n","        for key, val in params.items():\n","            self.params[key] = val\n","\n","        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n","            self.layers[key].W = self.params['W' + str(i+1)]\n","            self.layers[key].b = self.params['b' + str(i+1)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TX6CnJfKSqe6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Stochastic Gradient Descent\n","class SGD:\n","    def __init__(self, lr=0.01):\n","        self.lr = lr\n","    \n","    def update(self, params, grads):\n","        for key in params.keys():\n","            params[key] -= self.lr * grads[key]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lgW2GFSJSqe8","colab_type":"code","colab":{}},"cell_type":"code","source":["# Momentum\n","# v <- αV - η*dL/dW\n","# W <- W + v\n","# vは速度, -η*dL/dWが加速度\n","# 勾配がきつい所ほど、更新の値が大きい\n","# α 減速項\n","\n","class Momentum:\n","    def __init__(self, lr=0.01, momentum=0.9):\n","        self.lr = lr\n","        self.momentum = momentum\n","        self.v = None\n","    \n","    def update(self, params, grads):\n","        if self.v is None:\n","            self.v = {}\n","            for key, val in params.items():\n","                self.v[key] = np.zeros_like(val)\n","        \n","        for key in params.keys():\n","            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n","            params[key] += self.v[key]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gMAtpW-ySqe9","colab_type":"code","colab":{}},"cell_type":"code","source":["# AdaGrad\n","# learning rate decay 徐々に学習係数を小さくする\n","# 学習係数を全体で一括して下げるのではなく、一つ一つのパラメータに対して個々で減衰させる\n","# h <- dL/dW ⦿ dL/dW ※⦿は要素毎の掛け算 つまりhは勾配の２乗和を加算したもの\n","# W <- W - (η/√h) * dL/dW\n","# hは学習が進むに連れて、大きくなるが逓減する\n","# 1/√hはh=0で無限大、hが増加するに連れて小さくなる\n","\n","class AdaGrad:\n","    def __init__(self, lr=0.01):\n","        self.lr = lr\n","        self.h = None\n","        \n","    def update(self, params, grads):\n","        if self.h is None:\n","            self.h = {}\n","            for key, val in params.items():\n","                self.h[key] = np.zeros_like(val)\n","        \n","        for key in params.keys():\n","            self.h[key] += grads[key] * grads[key]\n","            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sJLsZdTRSqe_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Adam ≒　Momentum + AdaGrad\n","class Adam:\n","    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n","        self.lr = lr\n","        self.beta1 = beta1\n","        self.beta2 = beta2\n","        self.iter = 0\n","        self.m = None\n","        self.v = None\n","        self.h = 1e-7 # ゼロ割防止の為の微小値\n","\n","    def update(self, params, grads):\n","        if self.m is None:\n","            self.m, self.v = {}, {}\n","            for key, val in params.items():\n","                self.m[key] = np.zeros_like(val)\n","                self.v[key] = np.zeros_like(val)\n","\n","        self.iter += 1\n","        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n","\n","        for key, val in params.items():\n","            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n","            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n","            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + self.h)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VRmHveNzSqfA","colab_type":"code","colab":{}},"cell_type":"code","source":["class RMSprop:\n","    def __init__(self, lr=0.01, decay_rate=0.99):\n","        self.lr = lr\n","        self.decay_rate = decay_rate\n","        self.h = None\n","        self.e = 1e-7 # ゼロ割を防ぐための微小値\n","\n","    def update(self, params, grads):\n","        if self.h is None:\n","            self.h = {}\n","            for key, val in params.items():\n","                self.h[key] = np.zeros_like(val)\n","\n","        for key in params.keys():\n","            self.h[key] *= self.decay_rate\n","            self.h[key] += (1.0 - self.decay_rate) * grads[key] * grads[key]\n","            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + self.e)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rhcqFo4PSqfB","colab_type":"code","colab":{}},"cell_type":"code","source":["class Nesterov:\n","    def __init__(self, lr=0.01, momentum=0.9):\n","        self.lr = lr\n","        self.momentum = momentum\n","        self.v = None\n","\n","    def update(self, params, grads):\n","        if self.v is None:\n","            self.v = {}\n","            for key, val in params.items():\n","                self.v[key] = np.zeros_like(val)\n","\n","        for key in params.keys():\n","            self.v[key] *= self.v[key]\n","            self.v[key] -= self.lr * grads[key]\n","            params[key] += self.momentum * self.momentum * self.v[key]\n","            params[key] -= (1.0 + self.momentum) * self.lr * self.v[key]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w6xVr4XfSqfD","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"pnPd-YfmSqfE","colab_type":"code","colab":{}},"cell_type":"code","source":["import sys, os\n","import numpy as np\n","from mnist import load_mnist\n","\n","# データの読み込み\n","(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n","\n","# 処理に時間のかかる場合はデータを削減 \n","x_train, t_train = x_train[:5000], t_train[:5000]\n","x_test, t_test = x_test[:1000], t_test[:1000]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GS8TKK_GSqfF","colab_type":"code","colab":{}},"cell_type":"code","source":["class Trainer:\n","    \"\"\"ニューラルネットの訓練を行うクラス\n","    \"\"\"\n","    def __init__(self, network, x_train, t_train, x_test, t_test,\n","                 epochs=20, mini_batch_size=100,\n","                 optimizer='SGD', optimizer_param={'lr':0.01}, \n","                 evaluate_sample_num_per_epoch=None, verbose=True):\n","        self.network = network\n","        self.verbose = verbose\n","        self.x_train = x_train\n","        self.t_train = t_train\n","        self.x_test = x_test\n","        self.t_test = t_test\n","        self.epochs = epochs\n","        self.batch_size = mini_batch_size\n","        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch\n","\n","        # optimzer\n","        optimizer_class_dict = {'sgd':SGD, 'momentum':Momentum, 'nesterov':Nesterov,\n","                                'adagrad':AdaGrad, 'rmsprpo':RMSprop, 'adam':Adam}\n","        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)\n","        \n","        self.train_size = x_train.shape[0]\n","        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1)\n","        self.max_iter = int(epochs * self.iter_per_epoch)\n","        self.current_iter = 0\n","        self.current_epoch = 0\n","        \n","        self.train_loss_list = []\n","        self.train_acc_list = []\n","        self.test_acc_list = []\n","\n","    def train_step(self):\n","        batch_mask = np.random.choice(self.train_size, self.batch_size)\n","        x_batch = self.x_train[batch_mask]\n","        t_batch = self.t_train[batch_mask]\n","        \n","        grads = self.network.gradient(x_batch, t_batch)\n","        self.optimizer.update(self.network.params, grads)\n","        \n","        loss = self.network.loss(x_batch, t_batch)\n","        self.train_loss_list.append(loss)\n","        if self.verbose: print(\"train loss:\" + str(loss))\n","        \n","        if self.current_iter % self.iter_per_epoch == 0:\n","            self.current_epoch += 1\n","            \n","            x_train_sample, t_train_sample = self.x_train, self.t_train\n","            x_test_sample, t_test_sample = self.x_test, self.t_test\n","            if not self.evaluate_sample_num_per_epoch is None:\n","                t = self.evaluate_sample_num_per_epoch\n","                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]\n","                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]\n","                \n","            train_acc = self.network.accuracy(x_train_sample, t_train_sample)\n","            test_acc = self.network.accuracy(x_test_sample, t_test_sample)\n","            self.train_acc_list.append(train_acc)\n","            self.test_acc_list.append(test_acc)\n","\n","            if self.verbose: print(\"=== epoch:\" + str(self.current_epoch) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc) + \" ===\")\n","        self.current_iter += 1\n","\n","    def train(self):\n","        for i in range(self.max_iter):\n","            self.train_step()\n","\n","        test_acc = self.network.accuracy(self.x_test, self.t_test)\n","\n","        if self.verbose:\n","            print(\"=============== Final Test Accuracy ===============\")\n","            print(\"test acc:\" + str(test_acc))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ic9D0zYtSqfG","colab_type":"code","colab":{},"outputId":"a075ca86-e0ae-416b-e177-5e282fa8e476"},"cell_type":"code","source":["max_epochs = 20\n","\n","network = SimpleConvNet(input_dim=(1,28,28), \n","                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n","                        hidden_size=100, output_size=10, weight_init_std=0.01)\n","                        \n","trainer = Trainer(network, x_train, t_train, x_test, t_test,\n","                  epochs=max_epochs, mini_batch_size=100,\n","                  optimizer='Adam', optimizer_param={'lr': 0.001},\n","                  evaluate_sample_num_per_epoch=1000)\n","trainer.train()\n","\n","# パラメータの保存\n","network.save_params(\"params.pkl\")\n","print(\"Saved Network Parameters!\")\n","\n","# グラフの描画\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(max_epochs)\n","plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n","plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train loss:2.2987308863816347\n","=== epoch:1, train acc:0.271, test acc:0.217 ===\n","train loss:2.2966087278608907\n","train loss:2.292173087268165\n","train loss:2.288319501856595\n","train loss:2.2797741956333972\n","train loss:2.2646118442708927\n","train loss:2.2490996564925383\n","train loss:2.2265329470595274\n","train loss:2.209158381681098\n","train loss:2.1619132978922067\n","train loss:2.1556923698067187\n","train loss:2.1406208700333096\n","train loss:2.0607414525402747\n","train loss:1.991675404119468\n","train loss:1.9634372279918164\n","train loss:1.8694528787857112\n","train loss:1.814351391251882\n","train loss:1.6727484917487891\n","train loss:1.6016442983716102\n","train loss:1.6472877686388463\n","train loss:1.5556966662394769\n","train loss:1.5152726981640618\n","train loss:1.4833734985124403\n","train loss:1.2076168787001706\n","train loss:1.1885450387800176\n","train loss:1.1045256804736352\n","train loss:1.0962516824850197\n","train loss:1.092655406117911\n","train loss:0.9179880537771623\n","train loss:0.8157958754403026\n","train loss:0.8273218470835663\n","train loss:0.9329024752289024\n","train loss:0.6895026384171358\n","train loss:0.7028929707614852\n","train loss:0.758439335984166\n","train loss:0.6956442008476051\n","train loss:0.7184424956370462\n","train loss:0.6225990886356566\n","train loss:0.693324405886781\n","train loss:0.8083828134396385\n","train loss:0.7191810805695611\n","train loss:0.7517566788102026\n","train loss:0.523628942828611\n","train loss:0.5394982292414915\n","train loss:0.4655487928828532\n","train loss:0.5981266139270981\n","train loss:0.5231707806675895\n","train loss:0.5138110833490034\n","train loss:0.5996544706055734\n","train loss:0.5790144456508525\n","train loss:0.6000873141310941\n","=== epoch:2, train acc:0.815, test acc:0.802 ===\n","train loss:0.6426622655277378\n","train loss:0.542992221639849\n","train loss:0.661330582830448\n","train loss:0.4896414185753061\n","train loss:0.5118058008629627\n","train loss:0.6967483355246581\n","train loss:0.5159547488924692\n","train loss:0.2947605632958306\n","train loss:0.5746513772428955\n","train loss:0.4083619596770957\n","train loss:0.5287251187171894\n","train loss:0.4191500992790148\n","train loss:0.46232586418901944\n","train loss:0.5362155432496047\n","train loss:0.4261362814650023\n","train loss:0.4706096024417462\n","train loss:0.41409898872395273\n","train loss:0.44912204545669177\n","train loss:0.27240812735182174\n","train loss:0.48113230854314487\n","train loss:0.361585293996848\n","train loss:0.3459364874797992\n","train loss:0.4119790097525647\n","train loss:0.4023529956840411\n","train loss:0.3753677331252244\n","train loss:0.25749217624511933\n","train loss:0.33455671126097963\n","train loss:0.48712734618538406\n","train loss:0.37640764149786277\n","train loss:0.3489073818457144\n","train loss:0.2951840409399798\n","train loss:0.3174955581619241\n","train loss:0.393887591192629\n","train loss:0.5089797833687131\n","train loss:0.28676619992287855\n","train loss:0.3322120946781547\n","train loss:0.4159122364856785\n","train loss:0.4232954552025406\n","train loss:0.658120446861963\n","train loss:0.3610593553639655\n","train loss:0.367460433255451\n","train loss:0.23928703323034878\n","train loss:0.48361744219340325\n","train loss:0.24800616988562002\n","train loss:0.48731310620598217\n","train loss:0.42723200480140433\n","train loss:0.4859343662896366\n","train loss:0.39205539240402026\n","train loss:0.364315624310906\n","train loss:0.27513386275616913\n","=== epoch:3, train acc:0.859, test acc:0.861 ===\n","train loss:0.38186490996343403\n","train loss:0.2536165410316469\n","train loss:0.4356448699489925\n","train loss:0.35473510042321243\n","train loss:0.2517643986886518\n","train loss:0.2647079242329313\n","train loss:0.2952303408665522\n","train loss:0.41917416801468105\n","train loss:0.2888134167750192\n","train loss:0.4207069623000271\n","train loss:0.21625963693473174\n","train loss:0.3236193147182524\n","train loss:0.24825016108690764\n","train loss:0.4986233518837336\n","train loss:0.4553240244927327\n","train loss:0.4225744206714173\n","train loss:0.23004795423865165\n","train loss:0.3588436261534353\n","train loss:0.37818447886944495\n","train loss:0.2837845640324214\n","train loss:0.3010976006246295\n","train loss:0.2780943388795147\n","train loss:0.31828445363062674\n","train loss:0.30903528673598557\n","train loss:0.19045890775492802\n","train loss:0.458251184066289\n","train loss:0.32187542488786147\n","train loss:0.3501827744889856\n","train loss:0.1463004430967939\n","train loss:0.17019771168186296\n","train loss:0.3794890916148645\n","train loss:0.31497718082598747\n","train loss:0.3257290369967232\n","train loss:0.29960919184273943\n","train loss:0.19231127602509987\n","train loss:0.20673879551629068\n","train loss:0.2876204158177972\n","train loss:0.31416763528779107\n","train loss:0.2584021598995727\n","train loss:0.22797625194783755\n","train loss:0.30852426730625776\n","train loss:0.24053999634910825\n","train loss:0.35040919731413417\n","train loss:0.23762853629407343\n","train loss:0.20045446055242575\n","train loss:0.28361715210432403\n","train loss:0.2444214571241996\n","train loss:0.3132108556509308\n","train loss:0.12634574800671075\n","train loss:0.2397310537826289\n","=== epoch:4, train acc:0.89, test acc:0.87 ===\n","train loss:0.3213151863812691\n","train loss:0.5611083789096929\n","train loss:0.21044358598535845\n","train loss:0.24421910263645277\n","train loss:0.16809605188377066\n","train loss:0.36885628791483716\n","train loss:0.19855016200893952\n","train loss:0.2984238597043603\n","train loss:0.23082560709044983\n","train loss:0.44336589504322865\n","train loss:0.2773840478012298\n","train loss:0.33091463562320406\n","train loss:0.20681670920582662\n","train loss:0.2439811630285809\n","train loss:0.19882550768369633\n","train loss:0.2209635244241838\n","train loss:0.31970107450145796\n","train loss:0.38379032891899323\n","train loss:0.2624417305267558\n","train loss:0.27745423388581186\n","train loss:0.4027059063449755\n","train loss:0.3559645041469862\n","train loss:0.2619016486468132\n","train loss:0.2882028913458631\n","train loss:0.19495630972574268\n","train loss:0.22522291146547474\n","train loss:0.19701879640402126\n","train loss:0.34920456661581695\n","train loss:0.24238267354811618\n","train loss:0.36179192408246785\n","train loss:0.34589788308832226\n","train loss:0.20010222698820745\n","train loss:0.3091992243664307\n","train loss:0.44300596401588066\n","train loss:0.21675327993724497\n","train loss:0.3544480321468311\n","train loss:0.41206923782043825\n","train loss:0.3058055053707855\n","train loss:0.32448220301170055\n","train loss:0.3243117130161937\n","train loss:0.23488678766005897\n","train loss:0.3506237434560521\n","train loss:0.5795026159574166\n","train loss:0.12568885795062715\n","train loss:0.19269133643401934\n","train loss:0.3136704777026192\n","train loss:0.15583201972719218\n","train loss:0.38196917490473603\n","train loss:0.26434210259263496\n","train loss:0.3047352409971531\n","=== epoch:5, train acc:0.906, test acc:0.891 ===\n","train loss:0.26024322891143337\n","train loss:0.2341667619059836\n","train loss:0.18340461634594843\n","train loss:0.24125659951423695\n","train loss:0.2818962762346778\n","train loss:0.4291634283228211\n","train loss:0.25511271202490104\n","train loss:0.29465303736598114\n","train loss:0.3226628435062399\n","train loss:0.19259473954107376\n","train loss:0.24920245132044305\n","train loss:0.2445854438448392\n","train loss:0.15247900021535415\n","train loss:0.3288528176799538\n","train loss:0.3314676778283778\n","train loss:0.21920606770656875\n","train loss:0.2037019537186854\n","train loss:0.2450463580660956\n","train loss:0.16323854881675134\n","train loss:0.19443197055168074\n","train loss:0.2689567859075186\n","train loss:0.217452548475115\n","train loss:0.23480283824058593\n","train loss:0.26097993301766886\n","train loss:0.1923461054324562\n","train loss:0.13357398063737233\n","train loss:0.2632091331759067\n","train loss:0.2979883746701983\n","train loss:0.3115423910920604\n","train loss:0.3804509089715306\n","train loss:0.22092496822205426\n","train loss:0.3068305807820155\n","train loss:0.262743289152098\n","train loss:0.18823926428065277\n","train loss:0.18284040632139942\n","train loss:0.23309850305822605\n","train loss:0.23975364183537873\n","train loss:0.1240348312669911\n","train loss:0.1875641807590404\n","train loss:0.20000416616744357\n","train loss:0.20536532553048978\n","train loss:0.10485400798312831\n","train loss:0.18992595507509782\n","train loss:0.26988625152421386\n","train loss:0.21310206673368914\n","train loss:0.3247584151831892\n","train loss:0.24393663717768907\n","train loss:0.2865935345488308\n","train loss:0.2550158238691603\n","train loss:0.35483507077092263\n","=== epoch:6, train acc:0.919, test acc:0.899 ===\n","train loss:0.2768569246128946\n","train loss:0.19347205335248416\n","train loss:0.3986829900275254\n","train loss:0.2328221564393192\n","train loss:0.10294537727787426\n","train loss:0.24646035245778872\n","train loss:0.16564382518408574\n","train loss:0.2304372850960289\n","train loss:0.1531594834161151\n","train loss:0.21936684697284556\n","train loss:0.23218992803206928\n"],"name":"stdout"},{"output_type":"stream","text":["train loss:0.2850639614431844\n","train loss:0.19106306766345252\n","train loss:0.2353225017922048\n","train loss:0.16218540060466385\n","train loss:0.29659965787402404\n","train loss:0.2192279472211648\n","train loss:0.21498048977670325\n","train loss:0.2695410465551765\n","train loss:0.26087717847567826\n","train loss:0.2604491184226302\n","train loss:0.26429431220332655\n","train loss:0.34384275735874253\n","train loss:0.29272175355456925\n","train loss:0.24432817014915273\n","train loss:0.16386062034889368\n","train loss:0.14978937775314813\n","train loss:0.2516251081256218\n","train loss:0.3160299156629773\n","train loss:0.2756743508991112\n","train loss:0.19118503320887018\n","train loss:0.21424390302676527\n","train loss:0.13343446595046204\n","train loss:0.2000212066630936\n","train loss:0.1414255076742932\n","train loss:0.22606262076338582\n","train loss:0.16925679384358144\n","train loss:0.17811347696856245\n","train loss:0.1383794271605833\n","train loss:0.1505504588944528\n","train loss:0.29748091908162044\n","train loss:0.1701895761194245\n","train loss:0.12861269011850285\n","train loss:0.10307485318237225\n","train loss:0.11890228687426717\n","train loss:0.21419175002821586\n","train loss:0.25346359016002584\n","train loss:0.27846176013185575\n","train loss:0.15099861077688767\n","train loss:0.11198639589274992\n","=== epoch:7, train acc:0.928, test acc:0.907 ===\n","train loss:0.21578604450470756\n","train loss:0.18290336975452065\n","train loss:0.2008618043893156\n","train loss:0.1838513994316728\n","train loss:0.21039170650048092\n","train loss:0.3091754001074301\n","train loss:0.20682008227981616\n","train loss:0.20274234019658788\n","train loss:0.18106969018770858\n","train loss:0.14017846238646758\n","train loss:0.1539553053351111\n","train loss:0.15991069114551223\n","train loss:0.18061514111240057\n","train loss:0.2880873145110961\n","train loss:0.2423070887997541\n","train loss:0.13827558210019056\n","train loss:0.14199870569050452\n","train loss:0.10655326126249796\n","train loss:0.11096648523695628\n","train loss:0.17524081593409818\n","train loss:0.21070753942923814\n","train loss:0.1139108734923559\n","train loss:0.08478643827665293\n","train loss:0.2715079334779549\n","train loss:0.17159095376951053\n","train loss:0.18844332935663505\n","train loss:0.22921133311548914\n","train loss:0.19614279501576778\n","train loss:0.20412975549507784\n","train loss:0.2091251868893251\n","train loss:0.07359925955860819\n","train loss:0.1116920985931031\n","train loss:0.3637641676387729\n","train loss:0.1168679598496768\n","train loss:0.08173402460640881\n","train loss:0.289587093795383\n","train loss:0.08615501250122003\n","train loss:0.17873987824649754\n","train loss:0.10970113419277094\n","train loss:0.1406493686016796\n","train loss:0.08060907018929686\n","train loss:0.14636851596208528\n","train loss:0.2550946449457809\n","train loss:0.20159633011160533\n","train loss:0.06154717268680308\n","train loss:0.15564839320684448\n","train loss:0.1338301391587372\n","train loss:0.1134155148115048\n","train loss:0.13515641474564766\n","train loss:0.3338835308907355\n","=== epoch:8, train acc:0.951, test acc:0.923 ===\n","train loss:0.07386243714045357\n","train loss:0.17374784193560788\n","train loss:0.1988490353238865\n","train loss:0.2436422412575896\n","train loss:0.18956113323734544\n","train loss:0.12563449543189165\n","train loss:0.1737375103052963\n","train loss:0.09176638207756442\n","train loss:0.17587092133974433\n","train loss:0.21579200813473473\n","train loss:0.2291609008327486\n","train loss:0.14110692882419282\n","train loss:0.13954180403180086\n","train loss:0.19414313799934896\n","train loss:0.14729537275984989\n","train loss:0.06931666844353022\n","train loss:0.2253040730105194\n","train loss:0.16376878803457762\n","train loss:0.16090511782631478\n","train loss:0.08452291176982082\n","train loss:0.0914334752292586\n","train loss:0.09908201234794095\n","train loss:0.15612334710964285\n","train loss:0.14781535362779188\n","train loss:0.12073638936413619\n","train loss:0.12876515611615316\n","train loss:0.24128921236962128\n","train loss:0.18374048170930501\n","train loss:0.1991038354814985\n","train loss:0.18611613333545227\n","train loss:0.18902842576142473\n","train loss:0.10980541939969346\n","train loss:0.1905755095293752\n","train loss:0.21788509213666696\n","train loss:0.10450453893698435\n","train loss:0.22974119289617825\n","train loss:0.22672033691686075\n","train loss:0.17100956480892557\n","train loss:0.06716223362126927\n","train loss:0.10767320072246327\n","train loss:0.11535079409940524\n","train loss:0.15917576033305916\n","train loss:0.22031877085493057\n","train loss:0.10715225203645487\n","train loss:0.16174861538678154\n","train loss:0.12253270639695739\n","train loss:0.12413293735862344\n","train loss:0.19990986695919108\n","train loss:0.13844489928366643\n","train loss:0.13973940602430854\n","=== epoch:9, train acc:0.942, test acc:0.914 ===\n","train loss:0.19381939052483613\n","train loss:0.2963885392330408\n","train loss:0.1720685996275334\n","train loss:0.095494554537909\n","train loss:0.12469627767495181\n","train loss:0.07611141866782152\n","train loss:0.23691253059976997\n","train loss:0.11819456236967095\n","train loss:0.11115300753518544\n","train loss:0.13137908109969249\n","train loss:0.2780328699910465\n","train loss:0.08930062019942835\n","train loss:0.11468885919347327\n","train loss:0.14457322979533527\n","train loss:0.09595869977719454\n","train loss:0.09555302374490292\n","train loss:0.04925208589783806\n","train loss:0.1785695190550139\n","train loss:0.12310284104516356\n","train loss:0.056840343607185505\n","train loss:0.176507069533268\n","train loss:0.07979877409866062\n","train loss:0.13153636809818917\n","train loss:0.057136317234472205\n","train loss:0.1387599605024311\n","train loss:0.22896422001589786\n","train loss:0.12274615390679115\n","train loss:0.10671581517165411\n","train loss:0.17564194011385556\n","train loss:0.14463074412621232\n","train loss:0.07993007852339326\n","train loss:0.1452423479168901\n","train loss:0.06335175880542118\n","train loss:0.11197814655000787\n","train loss:0.1567307295266027\n","train loss:0.1992086967770628\n","train loss:0.1384012115763869\n","train loss:0.1303838624080052\n","train loss:0.12752559449321288\n","train loss:0.1885365486700684\n","train loss:0.15787635806445435\n","train loss:0.09585042979484021\n","train loss:0.13796866384275325\n","train loss:0.13838935799840557\n","train loss:0.12239459400796587\n","train loss:0.10294828746571026\n","train loss:0.2309988244331612\n","train loss:0.10635839343677374\n","train loss:0.18252347946266861\n","train loss:0.17230705915027056\n","=== epoch:10, train acc:0.946, test acc:0.924 ===\n","train loss:0.08589705846948392\n","train loss:0.2420747540152687\n","train loss:0.18971619249283628\n","train loss:0.15733546216682093\n","train loss:0.06618079081079042\n","train loss:0.1701392681703343\n","train loss:0.1335887885859266\n","train loss:0.07507148957311907\n","train loss:0.14498103724697103\n","train loss:0.09988847902325622\n","train loss:0.13726534942952937\n","train loss:0.08682917275113747\n","train loss:0.08299016934792715\n","train loss:0.24174552956365541\n","train loss:0.08472786624443149\n","train loss:0.09632949250006875\n","train loss:0.1344999832523648\n","train loss:0.18503605706646398\n","train loss:0.13067626454962109\n","train loss:0.12017337944251517\n","train loss:0.10028373550545307\n","train loss:0.07662045271613856\n","train loss:0.061087168071619756\n","train loss:0.13676271118147684\n","train loss:0.06063588515705502\n","train loss:0.06252382322729581\n","train loss:0.14971012358203986\n","train loss:0.18397448254909624\n","train loss:0.18500443016081156\n","train loss:0.20240234284480807\n","train loss:0.15119087780712856\n","train loss:0.16191924716907152\n","train loss:0.10370004715946336\n","train loss:0.1289598973080333\n","train loss:0.1918345780439891\n","train loss:0.070776110546747\n","train loss:0.19253102456083201\n","train loss:0.08116063487905581\n","train loss:0.16869317051987923\n","train loss:0.1429773033435473\n","train loss:0.06493432535063913\n","train loss:0.10017503275628487\n","train loss:0.05197757231901892\n","train loss:0.14249068885095245\n","train loss:0.08696370531167222\n","train loss:0.10216891398522586\n","train loss:0.32931069309631084\n","train loss:0.1333132381703662\n","train loss:0.14636256192668395\n","train loss:0.10630147449270837\n","=== epoch:11, train acc:0.949, test acc:0.928 ===\n","train loss:0.15292103663742027\n","train loss:0.06627814076454705\n","train loss:0.23170654714975064\n","train loss:0.11399017284287902\n","train loss:0.16176829041294621\n","train loss:0.16416678905224547\n","train loss:0.08089530047943544\n","train loss:0.1064392622406525\n","train loss:0.10797641776683302\n","train loss:0.14076925840743879\n","train loss:0.07372449202799873\n","train loss:0.11890123945603367\n","train loss:0.08348925126640182\n","train loss:0.11354386287849767\n","train loss:0.1713329436018978\n","train loss:0.0881892021210502\n","train loss:0.07796538682537962\n","train loss:0.14440266617698289\n","train loss:0.13051911932043148\n","train loss:0.09641769227061388\n","train loss:0.14500419896961456\n"],"name":"stdout"},{"output_type":"stream","text":["train loss:0.14126987000135227\n","train loss:0.13512852082615015\n","train loss:0.09150061156427687\n","train loss:0.10321537710397279\n","train loss:0.04848165385438916\n","train loss:0.059895963734582676\n","train loss:0.09453561124216446\n","train loss:0.048425557553635715\n","train loss:0.07124974905834777\n","train loss:0.13420924464472236\n","train loss:0.1458283850276938\n","train loss:0.17353027161479498\n","train loss:0.11686165049011692\n","train loss:0.14633510173673067\n","train loss:0.17652725573879188\n","train loss:0.07441532407679978\n","train loss:0.1450142711710761\n","train loss:0.17799264193295466\n","train loss:0.15816998336895785\n","train loss:0.08717073903343418\n","train loss:0.13979540373918087\n","train loss:0.07784783386572239\n","train loss:0.10302191577173651\n","train loss:0.10164554475099384\n","train loss:0.10032834991048796\n","train loss:0.17736874361605828\n","train loss:0.076828107689313\n","train loss:0.2983186021406514\n","train loss:0.30624632014354997\n","=== epoch:12, train acc:0.953, test acc:0.943 ===\n","train loss:0.09160452671847187\n","train loss:0.09484047943110253\n","train loss:0.15415345449201148\n","train loss:0.058327827748441405\n","train loss:0.07162513909005082\n","train loss:0.049041676238139986\n","train loss:0.09460615236367048\n","train loss:0.17823680983613016\n","train loss:0.09537454893208999\n","train loss:0.07598988961143455\n","train loss:0.10943062343746647\n","train loss:0.05561293807313454\n","train loss:0.0963716431947809\n","train loss:0.04669283171320014\n","train loss:0.048981204763730364\n","train loss:0.06465379691186912\n","train loss:0.1178408165919759\n","train loss:0.09078174691247023\n","train loss:0.05349027685099881\n","train loss:0.08983386776383498\n","train loss:0.07240557641536566\n","train loss:0.029983294169143516\n","train loss:0.09609930123539179\n","train loss:0.1339045904191119\n","train loss:0.07272249962666946\n","train loss:0.06669432852688242\n","train loss:0.04748777237630558\n","train loss:0.17404882624588544\n","train loss:0.09412822753544696\n","train loss:0.0889583089818569\n","train loss:0.10945691825153388\n","train loss:0.06605196200925018\n","train loss:0.07080384416141983\n","train loss:0.14043459288418017\n","train loss:0.0739725659022437\n","train loss:0.06517956024887578\n","train loss:0.11796235605818803\n","train loss:0.11112188666784664\n","train loss:0.07108624755514337\n","train loss:0.1296696989313749\n","train loss:0.08767392891937613\n","train loss:0.0956120315129751\n","train loss:0.09147540153844971\n","train loss:0.1073341628386615\n","train loss:0.0974248887512778\n","train loss:0.0747658947065771\n","train loss:0.17293717044070525\n","train loss:0.06326098096931548\n","train loss:0.056214195400378086\n","train loss:0.13569582660908452\n","=== epoch:13, train acc:0.968, test acc:0.939 ===\n","train loss:0.030129149533457755\n","train loss:0.06766872186155183\n","train loss:0.1172107915274502\n","train loss:0.0867719263989067\n","train loss:0.0796027804485422\n","train loss:0.11167558540616028\n","train loss:0.09949017559641839\n","train loss:0.05659557541725864\n","train loss:0.09461320142275768\n","train loss:0.0422173801350188\n","train loss:0.07360483936281527\n","train loss:0.05911126873643254\n","train loss:0.07004244635654212\n","train loss:0.06419759179132634\n","train loss:0.053685128179255796\n","train loss:0.07837711556778239\n","train loss:0.08966131728167989\n","train loss:0.12553859158366185\n","train loss:0.051917111381121525\n","train loss:0.08725357501144457\n","train loss:0.0681019525134055\n","train loss:0.08615253538724561\n","train loss:0.15003008593827377\n","train loss:0.03925812518681717\n","train loss:0.06676677438405544\n","train loss:0.08117346687327798\n","train loss:0.15328572437839935\n","train loss:0.07861565614844411\n","train loss:0.05848986768294668\n","train loss:0.034685404569858316\n","train loss:0.04524076971201211\n","train loss:0.07182966484185498\n","train loss:0.07481908608754846\n","train loss:0.1589868566445052\n","train loss:0.14120999959628594\n","train loss:0.056578377073552656\n","train loss:0.12901992089874262\n","train loss:0.11585998774764747\n","train loss:0.06175626126097246\n","train loss:0.028441232293634048\n","train loss:0.08202871368206945\n","train loss:0.05787664649107506\n","train loss:0.08055567665369619\n","train loss:0.0811822419400104\n","train loss:0.15502135744569986\n","train loss:0.15201069453778657\n","train loss:0.07720537724384013\n","train loss:0.061298312160551996\n","train loss:0.10089723110402607\n","train loss:0.08954479030293722\n","=== epoch:14, train acc:0.968, test acc:0.947 ===\n","train loss:0.08545711258936611\n","train loss:0.06990232492468311\n","train loss:0.0969390046512891\n","train loss:0.09417060416635885\n","train loss:0.0718805889580153\n","train loss:0.026202885261414642\n","train loss:0.19911771695217376\n","train loss:0.04023072775525391\n","train loss:0.07849507261651928\n","train loss:0.06436669340693649\n","train loss:0.06929092350665114\n","train loss:0.10135815258487416\n","train loss:0.0546461282195879\n","train loss:0.05864786528751363\n","train loss:0.12091767136193177\n","train loss:0.08684196426545787\n","train loss:0.04079827902141216\n","train loss:0.103306386847421\n","train loss:0.051814786430145005\n","train loss:0.1031694645588334\n","train loss:0.13356971965745362\n","train loss:0.09949425876145301\n","train loss:0.08259558840600095\n","train loss:0.1018615666261677\n","train loss:0.10513962965829401\n","train loss:0.02611269457384623\n","train loss:0.0971325164210747\n","train loss:0.0785853210698771\n","train loss:0.05693922906715911\n","train loss:0.03646703164519659\n","train loss:0.05529770848252112\n","train loss:0.045427779607803975\n","train loss:0.04976207749751658\n","train loss:0.054485574905548256\n","train loss:0.03948633431051574\n","train loss:0.06158438855502992\n","train loss:0.02645472543018492\n","train loss:0.06899338586408249\n","train loss:0.06293652081051807\n","train loss:0.026280333468934075\n","train loss:0.0690718136803194\n","train loss:0.06397068180288176\n","train loss:0.058095537417414904\n","train loss:0.06824705098138367\n","train loss:0.02572425655285615\n","train loss:0.02297831028483616\n","train loss:0.07517036286260734\n","train loss:0.06211535672226026\n","train loss:0.046050833860365036\n","train loss:0.06221823940035173\n","=== epoch:15, train acc:0.976, test acc:0.947 ===\n","train loss:0.04902015723096186\n","train loss:0.046069510801846354\n","train loss:0.06890089463616769\n","train loss:0.03006304922437105\n","train loss:0.09908370422477215\n","train loss:0.1580497637893018\n","train loss:0.08941217249530331\n","train loss:0.05982083339935654\n","train loss:0.06259243004575236\n","train loss:0.06607694237389505\n","train loss:0.021482186919962783\n","train loss:0.03459894889575983\n","train loss:0.03457120264312398\n","train loss:0.06514590397963037\n","train loss:0.04536578123089587\n","train loss:0.026272006007520533\n","train loss:0.1127064748604361\n","train loss:0.02878415991379453\n","train loss:0.04781133127098322\n","train loss:0.0575593774511007\n","train loss:0.04017488393998594\n","train loss:0.036584657303219636\n","train loss:0.047445595119107405\n","train loss:0.048763982801301904\n","train loss:0.024850225843653262\n","train loss:0.033680228684231435\n","train loss:0.07364679329945009\n","train loss:0.02258139623559333\n","train loss:0.028369564768652288\n","train loss:0.06990676853674806\n","train loss:0.06364659834440106\n","train loss:0.08736975326754332\n","train loss:0.061940297447491896\n","train loss:0.06412094472263677\n","train loss:0.039322083105352464\n","train loss:0.05670868919179736\n","train loss:0.0395892143724939\n","train loss:0.036921016211543936\n","train loss:0.034826919786340546\n","train loss:0.013032145101718568\n","train loss:0.05766143109298485\n","train loss:0.03616147876912884\n","train loss:0.061816808987319886\n","train loss:0.07831362052120078\n","train loss:0.0959406566235749\n","train loss:0.035570624347784845\n","train loss:0.03277341776139966\n","train loss:0.02140108415298267\n","train loss:0.025693220557523357\n","train loss:0.03388230451524478\n","=== epoch:16, train acc:0.976, test acc:0.946 ===\n","train loss:0.03967585290816193\n","train loss:0.04354800822271441\n","train loss:0.040305972305488345\n","train loss:0.06180205768582895\n","train loss:0.018809238817246415\n","train loss:0.060407358661468694\n","train loss:0.03568215546380011\n","train loss:0.13218976948599023\n","train loss:0.024889175319221194\n","train loss:0.07076659461924194\n","train loss:0.03761715358351203\n","train loss:0.06418990346874659\n","train loss:0.06205329737334685\n","train loss:0.02853056254241221\n","train loss:0.07569276387529036\n","train loss:0.021500256202749396\n","train loss:0.0915695546936529\n","train loss:0.043719120735124635\n","train loss:0.030526870060395516\n","train loss:0.058087459303871845\n","train loss:0.0339543418942541\n","train loss:0.05505416987559226\n","train loss:0.042072629022353196\n","train loss:0.0402665972132061\n","train loss:0.023389195487763928\n","train loss:0.04556527449285115\n","train loss:0.031001313426587143\n"],"name":"stdout"},{"output_type":"stream","text":["train loss:0.1137967444651696\n","train loss:0.017617510749506633\n","train loss:0.03963822803689172\n","train loss:0.04334864551282316\n","train loss:0.04088370106385108\n","train loss:0.046762804741415344\n","train loss:0.07314510096897169\n","train loss:0.07153432690980872\n","train loss:0.031055264279654046\n","train loss:0.046215643300072745\n","train loss:0.04043058897265928\n","train loss:0.0461516453807534\n","train loss:0.01937763344060239\n","train loss:0.04010768704127577\n","train loss:0.05612311024920512\n","train loss:0.030031695664608428\n","train loss:0.09147004083753815\n","train loss:0.08291583942090103\n","train loss:0.027740717386860406\n","train loss:0.01671395386088276\n","train loss:0.029951995154909757\n","train loss:0.028659739027530426\n","train loss:0.043586186662504\n","=== epoch:17, train acc:0.986, test acc:0.951 ===\n","train loss:0.022377125504381624\n","train loss:0.047809029432742525\n","train loss:0.04326756007765105\n","train loss:0.028049798588236734\n","train loss:0.03917882542000939\n","train loss:0.059154610113620484\n","train loss:0.043883736624429986\n","train loss:0.06508634524038995\n","train loss:0.12785400069653818\n","train loss:0.07720080650704357\n","train loss:0.05902235653919157\n","train loss:0.04572641686219593\n","train loss:0.030775051450295604\n","train loss:0.033868711278233626\n","train loss:0.14068708480105227\n","train loss:0.04216767952265197\n","train loss:0.07428300893276835\n","train loss:0.05215910314606664\n","train loss:0.021012231598376688\n","train loss:0.05143638782866604\n","train loss:0.09064114919887366\n","train loss:0.058696313788537784\n","train loss:0.062083224065185176\n","train loss:0.018125519790898194\n","train loss:0.03207595253276316\n","train loss:0.03871125806439117\n","train loss:0.029339566532123308\n","train loss:0.028159602669829704\n","train loss:0.09959986542074546\n","train loss:0.08698963315874904\n","train loss:0.027795900990220505\n","train loss:0.043168654934314266\n","train loss:0.04918259474563091\n","train loss:0.05799905230667106\n","train loss:0.018238181472697547\n","train loss:0.03432920065088375\n","train loss:0.03714597880485344\n","train loss:0.07552170603916722\n","train loss:0.06058841829400558\n","train loss:0.035877554614582585\n","train loss:0.052481504635766486\n","train loss:0.019179046118957627\n","train loss:0.033338563006743704\n","train loss:0.058379870036445854\n","train loss:0.03429569857511928\n","train loss:0.01681673753217459\n","train loss:0.06867938152742284\n","train loss:0.02423097522656408\n","train loss:0.07053029256984127\n","train loss:0.023897816170319244\n","=== epoch:18, train acc:0.977, test acc:0.95 ===\n","train loss:0.062356402631669916\n","train loss:0.045268889567919066\n","train loss:0.027827747765520317\n","train loss:0.05899435956287838\n","train loss:0.02390762173329799\n","train loss:0.02884844954359051\n","train loss:0.10619942812015382\n","train loss:0.02480157310163555\n","train loss:0.03418812795585496\n","train loss:0.04770888043542154\n","train loss:0.034849045953367616\n","train loss:0.06163221601211858\n","train loss:0.058328883322168575\n","train loss:0.04060294627805205\n","train loss:0.03239679378294292\n","train loss:0.02345583652011248\n","train loss:0.024117744325319036\n","train loss:0.05094816208068078\n","train loss:0.06349409693357339\n","train loss:0.14179637278605756\n","train loss:0.03078203716633023\n","train loss:0.03546689757214208\n","train loss:0.02125496688646809\n","train loss:0.0384905066509842\n","train loss:0.03956209907849487\n","train loss:0.022655727135166885\n","train loss:0.052884039458301065\n","train loss:0.025371651057192\n","train loss:0.09103201354760111\n","train loss:0.03629177159624292\n","train loss:0.043068938769553346\n","train loss:0.06824918026415022\n","train loss:0.019823244245998656\n","train loss:0.027013035413185824\n","train loss:0.044231956952646125\n","train loss:0.06335394827082665\n","train loss:0.016186030903915582\n","train loss:0.03882655565832085\n","train loss:0.0354479421039679\n","train loss:0.027338236534784382\n","train loss:0.058013202856832514\n","train loss:0.015411097796075288\n","train loss:0.023916585932322466\n","train loss:0.009281025234096015\n","train loss:0.013324525675496192\n","train loss:0.02992950136086507\n","train loss:0.04838047422483566\n","train loss:0.013260658866546635\n","train loss:0.03072957581795766\n","train loss:0.02620946223314629\n","=== epoch:19, train acc:0.991, test acc:0.957 ===\n","train loss:0.02465321711499732\n","train loss:0.023296859979813275\n","train loss:0.02238115577140642\n","train loss:0.0183697223332077\n","train loss:0.02115147890141476\n","train loss:0.01784498151475329\n","train loss:0.03442392023778005\n","train loss:0.02522934200573105\n","train loss:0.01614726151923203\n","train loss:0.07851641996862142\n","train loss:0.04366167396210803\n","train loss:0.030192457399563288\n","train loss:0.020901069841549557\n","train loss:0.0314916665766689\n","train loss:0.008976333659290089\n","train loss:0.08611165007253971\n","train loss:0.07792160281189882\n","train loss:0.042114785852918224\n","train loss:0.0154772892689199\n","train loss:0.1021695422055238\n","train loss:0.023291905022659362\n","train loss:0.04137263878003718\n","train loss:0.0353308927722301\n","train loss:0.030175341680032473\n","train loss:0.06909586015247599\n","train loss:0.030696865709209455\n","train loss:0.022790659324823593\n","train loss:0.047551208038382115\n","train loss:0.02688530465808404\n","train loss:0.014623212500517261\n","train loss:0.034735102771534965\n","train loss:0.03387371459887923\n","train loss:0.01673216831060722\n","train loss:0.028981679429307343\n","train loss:0.1177234625715944\n","train loss:0.08232829856310019\n","train loss:0.03683612852044045\n","train loss:0.0280781214383632\n","train loss:0.009552793553885226\n","train loss:0.02015974435533228\n","train loss:0.015383771841599917\n","train loss:0.052468078521673886\n","train loss:0.009996900159337813\n","train loss:0.02837354071548008\n","train loss:0.022380301658624327\n","train loss:0.02570924350952728\n","train loss:0.03073066698154674\n","train loss:0.07629765751185595\n","train loss:0.032518345390759144\n","train loss:0.058965736774588995\n","=== epoch:20, train acc:0.986, test acc:0.956 ===\n","train loss:0.02123334512078804\n","train loss:0.022349320831072376\n","train loss:0.045802270754189675\n","train loss:0.021078632837912\n","train loss:0.06794853932189932\n","train loss:0.03318490765000293\n","train loss:0.023057895209096804\n","train loss:0.05147748673715788\n","train loss:0.034481514314449985\n","train loss:0.0404174637681832\n","train loss:0.02590767153696528\n","train loss:0.044477244018396256\n","train loss:0.02947147493431058\n","train loss:0.01868539448138778\n","train loss:0.02731221672563728\n","train loss:0.01848647329655049\n","train loss:0.020953440923981596\n","train loss:0.018232654978548524\n","train loss:0.025269736992029165\n","train loss:0.01957433338762802\n","train loss:0.008166086994450263\n","train loss:0.030622075640656318\n","train loss:0.011704513444955133\n","train loss:0.0590250297207112\n","train loss:0.018900633677548583\n","train loss:0.022102145603444083\n","train loss:0.01932368430025178\n","train loss:0.03519822435547595\n","train loss:0.009359849785731253\n","train loss:0.1426900729167453\n","train loss:0.01772447653094261\n","train loss:0.016701494110940313\n","train loss:0.019160808117099443\n","train loss:0.015110203962244793\n","train loss:0.017681072287509005\n","train loss:0.03820124927724382\n","train loss:0.020208069626716407\n","train loss:0.02029413536153957\n","train loss:0.020797717281289284\n","train loss:0.05525910673852047\n","train loss:0.014533167811658056\n","train loss:0.014564065919481584\n","train loss:0.01844024196767237\n","train loss:0.01971048091239896\n","train loss:0.01722026198080152\n","train loss:0.00973076120491985\n","train loss:0.03545306695388792\n","train loss:0.021146292352590877\n","train loss:0.033448169297880914\n","=============== Final Test Accuracy ===============\n","test acc:0.955\n","Saved Network Parameters!\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x110d83c50>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"j9C1ylOvSqfJ","colab_type":"code","colab":{},"outputId":"c30682f0-260d-482b-8a24-6332658de762"},"cell_type":"code","source":["def filter_show(filters, nx=8, margin=3, scale=10):\n","    \"\"\"\n","    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n","    \"\"\"\n","    FN, C, FH, FW = filters.shape\n","    ny = int(np.ceil(FN / nx))\n","\n","    fig = plt.figure()\n","    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n","\n","    for i in range(FN):\n","        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n","        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n","    plt.show()\n","\n","\n","network = SimpleConvNet()\n","# ランダム初期化後の重み\n","filter_show(network.params['W1'])\n","\n","# 学習後の重み\n","network.load_params(\"params.pkl\")\n","filter_show(network.params['W1'])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noRQBAHAoRQAAHEoRAADnvwDw6e21eIcqUwAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x110dc69e8>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLxIL4PMAAAAASUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x11194deb8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"6YX1D87OSqfM","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}